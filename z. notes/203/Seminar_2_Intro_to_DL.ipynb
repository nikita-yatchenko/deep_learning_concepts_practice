{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Оптимизация нейронных сетей. Метод обратного распространения ошибки (ноутбук)\n",
    "\n",
    "> Узнаем как устроена оптимизация нейронных сетей. Оптимизация в `PyTorch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## План ноутбука\n",
    "\n",
    "1. Высокоуровневое API для обучение нейросетей в `PyTorch`\n",
    "2. Обучение первой нейросети в `PyTorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Высокоуровневое API для обучение нейросетей в `PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Создание объекта нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(700, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "net = nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [\n",
    "            ('linear1', nn.Linear(700, 500)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('linear2', nn.Linear(500, 200)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('linear3', nn.Linear(200, 10))\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (linear2): Linear(in_features=500, out_features=200, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (linear3): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=700, out_features=500, bias=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.rand(6, 700)\n",
    "\n",
    "net(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTaskNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(700, 500)\n",
    "        self.linear3 = nn.Linear(500, 10)\n",
    "        self.linear2 = nn.Linear(500, 500)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.activation(self.linear1(x))\n",
    "        output = self.activation(self.linear2(output))\n",
    "        output = self.activation(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net = CustomTaskNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CustomTaskNetwork(\\n  (linear1): Linear(in_features=700, out_features=500, bias=True)\\n  (linear3): Linear(in_features=500, out_features=10, bias=True)\\n  (linear2): Linear(in_features=500, out_features=500, bias=True)\\n  (activation): ReLU()\\n)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1047,  0.0018, -0.0319,  0.0088,  0.0206, -0.0232, -0.0438, -0.0296,\n",
       "         -0.0596,  0.0264],\n",
       "        [ 0.0695, -0.0082, -0.0272,  0.0197,  0.0149, -0.0096, -0.0450, -0.0269,\n",
       "         -0.0376,  0.0147],\n",
       "        [ 0.0836, -0.0125, -0.0277,  0.0262,  0.0144, -0.0084, -0.0455, -0.0274,\n",
       "         -0.0429,  0.0231],\n",
       "        [ 0.0628, -0.0069, -0.0311,  0.0112,  0.0018, -0.0231, -0.0261, -0.0272,\n",
       "         -0.0663,  0.0373],\n",
       "        [ 0.0950,  0.0019, -0.0376,  0.0258,  0.0259, -0.0222, -0.0506, -0.0409,\n",
       "         -0.0361,  0.0272],\n",
       "        [ 0.0803, -0.0290, -0.0264, -0.0017,  0.0162, -0.0159, -0.0376, -0.0209,\n",
       "         -0.0666,  0.0297]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTaskNetwork(\n",
       "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTaskNetwork(\n",
       "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 3.5266e-02,  5.7545e-03, -3.4416e-02,  ..., -2.6693e-02,\n",
       "         -3.0254e-02, -5.2823e-03],\n",
       "        [-4.8144e-03,  1.9251e-02, -1.7009e-02,  ..., -8.3402e-03,\n",
       "         -3.5727e-02, -3.1722e-02],\n",
       "        [ 2.5009e-02, -2.3408e-02, -2.4295e-02,  ..., -5.3888e-03,\n",
       "          8.9848e-03,  3.1952e-02],\n",
       "        ...,\n",
       "        [ 3.3807e-02,  2.1817e-03,  8.7364e-03,  ..., -3.3118e-02,\n",
       "         -7.7291e-05,  3.4851e-02],\n",
       "        [ 1.2947e-02,  3.3807e-02, -3.7735e-02,  ...,  1.5305e-02,\n",
       "          1.3197e-02, -1.5404e-02],\n",
       "        [ 1.6492e-02, -1.9562e-02, -5.0703e-03,  ..., -2.2453e-02,\n",
       "         -3.2365e-02,  1.2563e-02]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train()\n",
    "net.eval()\n",
    "\n",
    "net.linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 3.5266e-02,  5.7545e-03, -3.4416e-02,  ..., -2.6693e-02,\n",
       "          -3.0254e-02, -5.2823e-03],\n",
       "         [-4.8144e-03,  1.9251e-02, -1.7009e-02,  ..., -8.3402e-03,\n",
       "          -3.5727e-02, -3.1722e-02],\n",
       "         [ 2.5009e-02, -2.3408e-02, -2.4295e-02,  ..., -5.3888e-03,\n",
       "           8.9848e-03,  3.1952e-02],\n",
       "         ...,\n",
       "         [ 3.3807e-02,  2.1817e-03,  8.7364e-03,  ..., -3.3118e-02,\n",
       "          -7.7291e-05,  3.4851e-02],\n",
       "         [ 1.2947e-02,  3.3807e-02, -3.7735e-02,  ...,  1.5305e-02,\n",
       "           1.3197e-02, -1.5404e-02],\n",
       "         [ 1.6492e-02, -1.9562e-02, -5.0703e-03,  ..., -2.2453e-02,\n",
       "          -3.2365e-02,  1.2563e-02]]),\n",
       " Parameter containing:\n",
       " tensor([-8.9737e-03, -2.8011e-02, -1.7497e-02, -3.1679e-02, -1.2169e-02,\n",
       "         -3.7304e-02,  8.6797e-04, -1.5913e-02, -5.3632e-03, -1.1712e-02,\n",
       "          1.3446e-02, -3.5661e-02,  1.7712e-02, -3.4449e-02,  3.1551e-02,\n",
       "         -5.8992e-03,  2.5977e-03, -2.6701e-02, -1.8009e-02,  2.2785e-02,\n",
       "          3.0546e-02, -3.6360e-03, -1.9009e-02, -2.9282e-02, -1.5521e-02,\n",
       "          4.4236e-03,  1.1506e-03, -3.2206e-02, -1.5879e-02,  3.0385e-02,\n",
       "          2.7589e-02, -3.0279e-02, -2.3494e-03, -3.2146e-02,  3.2560e-02,\n",
       "          2.7510e-02, -1.6275e-02,  2.4497e-02, -2.2980e-02, -3.1411e-02,\n",
       "          1.8908e-02, -1.2419e-02, -2.9374e-02,  2.0183e-02, -2.7791e-03,\n",
       "         -2.8611e-02, -3.4616e-02, -2.0105e-02, -1.3601e-02,  6.8507e-03,\n",
       "          1.1241e-02, -2.8677e-02, -1.5932e-02, -3.3600e-03, -2.3516e-02,\n",
       "          3.1179e-02, -3.2283e-03,  2.7280e-03, -1.6169e-02, -3.0204e-03,\n",
       "          7.6628e-03,  8.4112e-03,  3.5963e-02,  3.4421e-02, -3.5557e-02,\n",
       "         -3.0338e-02, -2.1013e-02, -9.6464e-03,  2.9266e-03, -1.6460e-02,\n",
       "          3.5323e-02,  2.4693e-02,  3.3591e-03, -2.6443e-02, -1.9645e-02,\n",
       "         -8.1150e-03, -2.2893e-02, -3.3143e-02, -2.1016e-02,  2.5776e-02,\n",
       "          1.4695e-02,  2.6393e-02, -3.7075e-02, -2.6075e-02,  1.7563e-02,\n",
       "         -4.2136e-03,  2.7070e-02,  3.5387e-02,  2.7185e-02,  1.0113e-02,\n",
       "         -1.2043e-02,  2.1303e-03,  1.6472e-02, -9.2460e-03, -2.7916e-02,\n",
       "          2.2818e-02, -2.0333e-02,  2.4057e-02, -2.7549e-02, -3.1657e-02,\n",
       "         -3.3777e-02,  3.4735e-02,  2.1888e-02,  4.5835e-03, -1.4555e-02,\n",
       "          2.0063e-02,  1.4195e-02, -3.1953e-02, -2.0074e-02, -3.2204e-02,\n",
       "          3.5814e-03,  1.0501e-03, -3.1710e-02,  1.1809e-04, -1.2138e-02,\n",
       "          4.9693e-03,  3.7365e-02,  1.5454e-02, -1.5525e-02,  3.6330e-02,\n",
       "          2.3244e-02, -4.1283e-03, -2.1559e-02, -3.5393e-02,  2.5753e-02,\n",
       "         -2.7650e-02,  1.0564e-02, -2.0633e-03, -6.2235e-03, -3.3378e-02,\n",
       "          7.0940e-03, -1.3188e-02,  1.9582e-02, -1.6225e-02, -4.0062e-03,\n",
       "          2.8845e-02, -3.5654e-02,  3.6854e-02,  2.3743e-02, -7.5795e-03,\n",
       "         -6.5061e-03,  5.2420e-03, -9.8629e-03,  1.8867e-03,  1.2842e-02,\n",
       "          2.0273e-02,  2.9381e-02, -2.1800e-02,  2.3518e-02, -1.2788e-02,\n",
       "         -8.8235e-03,  2.3487e-02, -1.6156e-02,  2.9464e-02, -2.0152e-02,\n",
       "         -1.6385e-02,  1.7309e-02, -3.4159e-02,  1.2881e-02, -1.2914e-02,\n",
       "          3.5814e-02,  1.9460e-02, -1.6026e-03,  2.1766e-02, -2.9959e-02,\n",
       "          1.1944e-02, -2.0444e-03, -2.5963e-02, -2.9175e-03,  1.7178e-02,\n",
       "         -3.7437e-02,  1.4013e-02, -1.9431e-02,  2.4797e-02,  3.2882e-02,\n",
       "         -1.5557e-02,  5.5834e-03,  6.1212e-03, -1.0898e-02, -6.3031e-04,\n",
       "          1.5165e-02,  8.0358e-04,  1.6443e-02,  1.5373e-02, -3.5048e-02,\n",
       "          1.1353e-02, -1.7312e-02, -9.6346e-03,  8.1589e-05,  2.1654e-02,\n",
       "          1.6522e-02,  1.1351e-02,  1.9483e-03, -2.2803e-03,  9.6486e-03,\n",
       "         -2.5567e-02,  2.5884e-02,  1.2207e-02, -2.0659e-02,  2.3572e-02,\n",
       "         -2.5166e-02,  1.5677e-02,  3.7770e-02,  5.6717e-03,  1.9296e-02,\n",
       "          4.2178e-03, -1.7280e-02, -2.4301e-02,  5.6029e-03,  9.9075e-03,\n",
       "         -2.1839e-02,  2.2465e-02, -2.8607e-03, -2.4094e-03,  1.0808e-02,\n",
       "         -3.0449e-02,  1.4691e-04,  2.5994e-02,  7.2080e-03,  3.1278e-02,\n",
       "         -1.4041e-02,  3.6271e-03,  2.3577e-02, -7.1508e-03, -1.3292e-02,\n",
       "         -3.0473e-02,  6.3020e-03,  6.1840e-03, -1.6955e-02,  1.8431e-02,\n",
       "         -2.0077e-02,  2.8111e-02,  3.8735e-03, -1.2408e-03, -2.8795e-02,\n",
       "          1.0390e-02, -1.8146e-02, -3.0289e-02, -2.1248e-02,  7.3034e-03,\n",
       "         -1.7861e-02, -2.0177e-02, -7.9841e-03,  3.4977e-02,  2.5351e-02,\n",
       "          7.8891e-04,  2.6979e-02,  2.9477e-02,  1.9782e-02, -3.9929e-03,\n",
       "         -2.7585e-02, -1.0834e-03,  1.8859e-02, -1.0468e-02, -2.0693e-02,\n",
       "         -2.0113e-02, -3.3588e-02, -2.4661e-02, -1.9052e-02, -1.0504e-03,\n",
       "         -3.0458e-04,  1.4694e-02,  2.0873e-02, -2.3765e-02, -2.5492e-02,\n",
       "         -3.2437e-02, -3.2428e-03,  2.5040e-03,  1.7903e-02,  9.6098e-03,\n",
       "          1.5131e-02, -3.0878e-02,  7.7369e-03,  1.3679e-02,  2.2921e-02,\n",
       "         -1.8897e-02, -3.3062e-03,  2.1512e-02, -8.4554e-03, -2.7257e-02,\n",
       "         -1.7414e-03,  2.5283e-02,  3.5004e-02,  3.0633e-02,  1.5544e-02,\n",
       "          2.2377e-02, -4.3818e-03, -2.6145e-02,  1.5190e-02,  2.2536e-03,\n",
       "          8.4437e-03, -1.4028e-02, -2.9536e-02, -3.8569e-03, -3.2770e-02,\n",
       "          9.3304e-03, -3.6596e-02,  4.9614e-03,  4.6834e-03,  3.0568e-02,\n",
       "          2.4537e-02, -1.3314e-02, -3.7748e-02,  2.0298e-03, -7.3051e-04,\n",
       "         -2.3027e-02, -2.5354e-02,  1.1625e-02, -3.7050e-02,  5.9533e-03,\n",
       "         -5.9811e-03, -2.0758e-02, -1.9196e-02,  1.2224e-02, -1.0941e-02,\n",
       "         -3.0791e-03,  1.6975e-02,  1.4312e-02, -1.7058e-03,  2.5583e-02,\n",
       "         -1.3548e-02,  2.8065e-02, -2.4338e-02,  2.5354e-02,  2.4403e-02,\n",
       "          2.3824e-02, -3.7312e-02, -2.4642e-02, -2.2840e-02,  5.4863e-03,\n",
       "         -2.7375e-02,  1.7714e-02,  1.1925e-02, -1.2807e-02, -3.6041e-02,\n",
       "         -1.0886e-02,  1.4045e-02,  3.4877e-02, -4.7550e-03,  2.1108e-02,\n",
       "         -1.4831e-02, -1.9791e-02, -1.6796e-02,  2.1588e-02,  1.8988e-02,\n",
       "         -2.2777e-02, -1.9215e-02,  1.2088e-02,  3.3492e-02,  5.2212e-03,\n",
       "         -3.4110e-03, -1.7846e-02,  2.3703e-02,  1.6383e-02,  1.2580e-02,\n",
       "          1.4622e-02,  1.1441e-03,  2.4278e-02,  1.7289e-02,  3.1487e-02,\n",
       "          8.6100e-03,  1.9806e-02, -2.0535e-02, -9.2880e-03, -1.9869e-03,\n",
       "         -2.8474e-02, -2.0860e-02, -2.3962e-02,  2.0568e-02, -1.0669e-02,\n",
       "         -7.4777e-03,  2.1776e-02, -3.4434e-02,  2.6616e-02,  2.4567e-02,\n",
       "         -2.5793e-02,  2.0102e-02, -1.1307e-03, -1.3128e-02, -9.7070e-03,\n",
       "          1.2548e-02, -3.4491e-02,  1.8203e-02,  3.5655e-02,  1.0726e-02,\n",
       "          2.6237e-02,  2.8553e-02, -2.9595e-02, -6.3798e-03, -2.9269e-02,\n",
       "          2.1378e-02,  6.9228e-03, -2.6589e-02, -2.5806e-02, -2.5673e-02,\n",
       "          1.5189e-02,  2.1111e-02,  1.5776e-02,  1.8792e-02, -2.6565e-03,\n",
       "         -4.4625e-04, -1.9235e-02,  3.3108e-02, -3.6888e-02,  3.0708e-03,\n",
       "          1.2239e-02, -2.4981e-02, -1.4447e-02, -9.0214e-03,  1.7646e-02,\n",
       "         -2.4630e-02,  9.8606e-03,  3.0057e-02,  3.6841e-02,  2.2315e-02,\n",
       "          1.6385e-02,  4.2118e-03,  1.9146e-02,  2.2059e-02,  1.8144e-02,\n",
       "         -2.9473e-03,  2.5274e-02,  5.1428e-03,  1.8131e-02,  3.1874e-03,\n",
       "          2.1597e-02,  3.5195e-02,  1.5433e-03,  1.1091e-02,  7.2222e-03,\n",
       "         -2.9119e-02, -2.2546e-02, -2.1124e-02,  2.9378e-02,  9.7948e-03,\n",
       "         -1.6006e-02, -2.1308e-02,  3.5734e-02,  1.6251e-02, -1.6977e-02,\n",
       "          2.0019e-02,  1.1105e-02,  2.7643e-02, -2.7027e-02,  2.8350e-02,\n",
       "         -1.0314e-02,  1.4091e-02, -3.6059e-02,  3.0883e-02,  9.5386e-03,\n",
       "         -1.8149e-02,  1.4066e-02,  2.8141e-02, -1.4700e-02,  2.2671e-02,\n",
       "          1.7108e-02, -2.9943e-02,  3.2694e-02, -2.1795e-02,  5.5886e-04,\n",
       "         -4.5157e-03, -5.8365e-03, -2.0803e-02,  3.8681e-03,  3.4405e-02,\n",
       "          2.0448e-02, -2.7468e-02, -2.4482e-02,  1.9683e-02, -9.3086e-04,\n",
       "         -2.5421e-02,  3.2681e-02,  1.4327e-02, -1.5231e-02,  1.9761e-03,\n",
       "          1.0300e-03,  2.2939e-02, -1.9479e-02, -5.2880e-03,  6.3539e-03,\n",
       "          1.2996e-02, -3.1024e-02,  3.3322e-02, -6.7613e-03, -1.5153e-02,\n",
       "          8.0522e-03,  1.5013e-02, -1.4091e-02, -9.8584e-03, -2.2063e-02,\n",
       "         -2.0716e-02, -3.3301e-02, -6.2972e-03, -3.5849e-03,  1.9089e-02,\n",
       "          2.7014e-02,  2.2307e-02, -1.5951e-02,  4.0382e-03, -1.0395e-02]),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0364,  0.0125,  0.0303,  ..., -0.0152,  0.0165,  0.0412],\n",
       "         [ 0.0365,  0.0436, -0.0335,  ..., -0.0119, -0.0079,  0.0179],\n",
       "         [ 0.0317,  0.0218,  0.0327,  ...,  0.0271,  0.0371,  0.0022],\n",
       "         ...,\n",
       "         [-0.0434, -0.0201, -0.0251,  ...,  0.0089,  0.0085, -0.0418],\n",
       "         [-0.0179, -0.0388, -0.0376,  ...,  0.0295,  0.0065,  0.0385],\n",
       "         [-0.0079,  0.0295, -0.0075,  ..., -0.0379, -0.0097, -0.0432]]),\n",
       " Parameter containing:\n",
       " tensor([-0.0411,  0.0034,  0.0043,  0.0268, -0.0413, -0.0385,  0.0368,  0.0144,\n",
       "          0.0273,  0.0406]),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0191, -0.0220, -0.0336,  ...,  0.0182,  0.0270,  0.0173],\n",
       "         [ 0.0439, -0.0374, -0.0326,  ...,  0.0143,  0.0408, -0.0415],\n",
       "         [ 0.0311, -0.0192, -0.0134,  ..., -0.0433,  0.0268, -0.0013],\n",
       "         ...,\n",
       "         [-0.0321, -0.0009, -0.0157,  ..., -0.0287, -0.0142, -0.0261],\n",
       "         [-0.0166,  0.0128, -0.0445,  ..., -0.0249,  0.0144,  0.0037],\n",
       "         [ 0.0350, -0.0356, -0.0355,  ...,  0.0258, -0.0251,  0.0287]]),\n",
       " Parameter containing:\n",
       " tensor([-0.0302,  0.0064,  0.0015, -0.0277,  0.0123, -0.0187,  0.0425,  0.0115,\n",
       "         -0.0407, -0.0282, -0.0068,  0.0140,  0.0141,  0.0065,  0.0239, -0.0296,\n",
       "         -0.0128,  0.0384,  0.0327, -0.0405,  0.0050, -0.0186, -0.0102, -0.0030,\n",
       "         -0.0250, -0.0393, -0.0030, -0.0401,  0.0092, -0.0024, -0.0374, -0.0443,\n",
       "         -0.0041,  0.0353,  0.0404, -0.0224,  0.0263,  0.0121,  0.0405,  0.0034,\n",
       "         -0.0417, -0.0043,  0.0057,  0.0095,  0.0136,  0.0081, -0.0018,  0.0397,\n",
       "          0.0128, -0.0288, -0.0311, -0.0070, -0.0286,  0.0114, -0.0438,  0.0180,\n",
       "         -0.0091, -0.0161, -0.0398,  0.0128,  0.0405,  0.0412,  0.0146, -0.0282,\n",
       "          0.0136, -0.0345, -0.0032, -0.0028, -0.0242,  0.0349, -0.0321, -0.0123,\n",
       "         -0.0364, -0.0121,  0.0286,  0.0315, -0.0132,  0.0062,  0.0119, -0.0024,\n",
       "          0.0392,  0.0005, -0.0388, -0.0098, -0.0100,  0.0024,  0.0021, -0.0081,\n",
       "          0.0349,  0.0136, -0.0312, -0.0431, -0.0376, -0.0146, -0.0092, -0.0029,\n",
       "         -0.0362, -0.0293, -0.0289, -0.0199,  0.0334,  0.0439,  0.0085,  0.0397,\n",
       "          0.0186,  0.0248,  0.0264, -0.0434,  0.0029,  0.0415,  0.0442, -0.0080,\n",
       "          0.0143,  0.0249,  0.0246, -0.0433,  0.0025, -0.0265,  0.0118, -0.0330,\n",
       "          0.0383,  0.0270,  0.0339, -0.0192,  0.0231, -0.0376, -0.0128,  0.0268,\n",
       "          0.0164, -0.0220, -0.0184, -0.0442, -0.0352, -0.0161,  0.0077,  0.0062,\n",
       "         -0.0293, -0.0347,  0.0095, -0.0419,  0.0375,  0.0343, -0.0302,  0.0108,\n",
       "          0.0212,  0.0429, -0.0412,  0.0420, -0.0212,  0.0141,  0.0010,  0.0324,\n",
       "          0.0203, -0.0010, -0.0072,  0.0259, -0.0230,  0.0380,  0.0123, -0.0132,\n",
       "          0.0121,  0.0361, -0.0009, -0.0252,  0.0199, -0.0351, -0.0389, -0.0040,\n",
       "          0.0381,  0.0011, -0.0362,  0.0227, -0.0310,  0.0208,  0.0315, -0.0322,\n",
       "         -0.0024,  0.0119,  0.0060, -0.0106,  0.0073, -0.0061,  0.0240, -0.0310,\n",
       "         -0.0290,  0.0231,  0.0298,  0.0361, -0.0265,  0.0444,  0.0225, -0.0176,\n",
       "         -0.0287, -0.0205, -0.0308,  0.0205,  0.0417, -0.0115,  0.0140, -0.0340,\n",
       "         -0.0145,  0.0251,  0.0225,  0.0113,  0.0249,  0.0183,  0.0025,  0.0017,\n",
       "          0.0128,  0.0407, -0.0064, -0.0306, -0.0052, -0.0337, -0.0182, -0.0407,\n",
       "         -0.0231,  0.0353,  0.0220, -0.0219,  0.0088, -0.0006,  0.0052, -0.0371,\n",
       "         -0.0343,  0.0200, -0.0138,  0.0009, -0.0048,  0.0275, -0.0318, -0.0423,\n",
       "         -0.0414, -0.0266,  0.0077,  0.0369, -0.0065,  0.0238,  0.0085,  0.0173,\n",
       "         -0.0239, -0.0126, -0.0274,  0.0201, -0.0276, -0.0101, -0.0369,  0.0139,\n",
       "          0.0021,  0.0325,  0.0241, -0.0311,  0.0076,  0.0110, -0.0136, -0.0016,\n",
       "         -0.0437,  0.0425,  0.0019, -0.0004, -0.0191, -0.0167, -0.0041, -0.0382,\n",
       "         -0.0348,  0.0090,  0.0358,  0.0379,  0.0284, -0.0096,  0.0328,  0.0372,\n",
       "          0.0028, -0.0318, -0.0124, -0.0049,  0.0426,  0.0193,  0.0180,  0.0142,\n",
       "          0.0395,  0.0188, -0.0230, -0.0251,  0.0270,  0.0076,  0.0269,  0.0169,\n",
       "          0.0396, -0.0399,  0.0249, -0.0375, -0.0170,  0.0293,  0.0083,  0.0164,\n",
       "          0.0149,  0.0231, -0.0012, -0.0059, -0.0302,  0.0387, -0.0242,  0.0401,\n",
       "          0.0174, -0.0096, -0.0441,  0.0205, -0.0111,  0.0233, -0.0397, -0.0146,\n",
       "         -0.0125, -0.0228,  0.0203, -0.0193, -0.0294, -0.0122, -0.0181,  0.0363,\n",
       "         -0.0181, -0.0046, -0.0179,  0.0014, -0.0157,  0.0073, -0.0080,  0.0300,\n",
       "         -0.0110,  0.0136, -0.0437,  0.0208, -0.0153,  0.0151,  0.0212, -0.0189,\n",
       "          0.0372,  0.0147,  0.0169, -0.0264, -0.0155, -0.0130,  0.0398,  0.0305,\n",
       "         -0.0417, -0.0406, -0.0364, -0.0276, -0.0307,  0.0314,  0.0214,  0.0058,\n",
       "         -0.0221, -0.0312,  0.0387, -0.0427, -0.0167, -0.0167, -0.0142,  0.0325,\n",
       "         -0.0272, -0.0235, -0.0263,  0.0068, -0.0320, -0.0366, -0.0412,  0.0233,\n",
       "          0.0294, -0.0236,  0.0260, -0.0236,  0.0017, -0.0156,  0.0108, -0.0406,\n",
       "          0.0126,  0.0253,  0.0223,  0.0390,  0.0186,  0.0147,  0.0226, -0.0365,\n",
       "         -0.0203, -0.0178,  0.0426,  0.0014,  0.0418, -0.0414,  0.0238, -0.0088,\n",
       "         -0.0229,  0.0099,  0.0182, -0.0334,  0.0310,  0.0096, -0.0087,  0.0054,\n",
       "         -0.0240, -0.0112, -0.0317, -0.0101, -0.0111,  0.0211, -0.0113, -0.0438,\n",
       "          0.0043, -0.0212, -0.0036, -0.0070,  0.0273,  0.0447, -0.0233, -0.0156,\n",
       "         -0.0136, -0.0248,  0.0312, -0.0362,  0.0295, -0.0011, -0.0097, -0.0196,\n",
       "          0.0049, -0.0078, -0.0307, -0.0120,  0.0323,  0.0349, -0.0136,  0.0365,\n",
       "         -0.0240, -0.0166,  0.0132,  0.0068, -0.0300, -0.0050, -0.0058,  0.0021,\n",
       "          0.0203,  0.0234,  0.0127,  0.0052,  0.0090, -0.0187, -0.0196, -0.0188,\n",
       "          0.0124,  0.0332, -0.0375,  0.0121,  0.0040,  0.0121, -0.0399, -0.0105,\n",
       "         -0.0411, -0.0234,  0.0395,  0.0101,  0.0412, -0.0228,  0.0009, -0.0132,\n",
       "         -0.0447,  0.0181,  0.0421,  0.0058, -0.0165, -0.0144, -0.0420,  0.0001,\n",
       "         -0.0260, -0.0132,  0.0029, -0.0152, -0.0248, -0.0111,  0.0384, -0.0436,\n",
       "          0.0175, -0.0316,  0.0353, -0.0352,  0.0445,  0.0198, -0.0282,  0.0402,\n",
       "         -0.0230, -0.0408,  0.0255, -0.0080, -0.0199, -0.0414,  0.0306, -0.0275,\n",
       "         -0.0085, -0.0179, -0.0235, -0.0102])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[ 3.5266e-02,  5.7545e-03, -3.4416e-02,  ..., -2.6693e-02,\n",
       "                       -3.0254e-02, -5.2823e-03],\n",
       "                      [-4.8144e-03,  1.9251e-02, -1.7009e-02,  ..., -8.3402e-03,\n",
       "                       -3.5727e-02, -3.1722e-02],\n",
       "                      [ 2.5009e-02, -2.3408e-02, -2.4295e-02,  ..., -5.3888e-03,\n",
       "                        8.9848e-03,  3.1952e-02],\n",
       "                      ...,\n",
       "                      [ 3.3807e-02,  2.1817e-03,  8.7364e-03,  ..., -3.3118e-02,\n",
       "                       -7.7291e-05,  3.4851e-02],\n",
       "                      [ 1.2947e-02,  3.3807e-02, -3.7735e-02,  ...,  1.5305e-02,\n",
       "                        1.3197e-02, -1.5404e-02],\n",
       "                      [ 1.6492e-02, -1.9562e-02, -5.0703e-03,  ..., -2.2453e-02,\n",
       "                       -3.2365e-02,  1.2563e-02]])),\n",
       "             ('linear1.bias',\n",
       "              tensor([-8.9737e-03, -2.8011e-02, -1.7497e-02, -3.1679e-02, -1.2169e-02,\n",
       "                      -3.7304e-02,  8.6797e-04, -1.5913e-02, -5.3632e-03, -1.1712e-02,\n",
       "                       1.3446e-02, -3.5661e-02,  1.7712e-02, -3.4449e-02,  3.1551e-02,\n",
       "                      -5.8992e-03,  2.5977e-03, -2.6701e-02, -1.8009e-02,  2.2785e-02,\n",
       "                       3.0546e-02, -3.6360e-03, -1.9009e-02, -2.9282e-02, -1.5521e-02,\n",
       "                       4.4236e-03,  1.1506e-03, -3.2206e-02, -1.5879e-02,  3.0385e-02,\n",
       "                       2.7589e-02, -3.0279e-02, -2.3494e-03, -3.2146e-02,  3.2560e-02,\n",
       "                       2.7510e-02, -1.6275e-02,  2.4497e-02, -2.2980e-02, -3.1411e-02,\n",
       "                       1.8908e-02, -1.2419e-02, -2.9374e-02,  2.0183e-02, -2.7791e-03,\n",
       "                      -2.8611e-02, -3.4616e-02, -2.0105e-02, -1.3601e-02,  6.8507e-03,\n",
       "                       1.1241e-02, -2.8677e-02, -1.5932e-02, -3.3600e-03, -2.3516e-02,\n",
       "                       3.1179e-02, -3.2283e-03,  2.7280e-03, -1.6169e-02, -3.0204e-03,\n",
       "                       7.6628e-03,  8.4112e-03,  3.5963e-02,  3.4421e-02, -3.5557e-02,\n",
       "                      -3.0338e-02, -2.1013e-02, -9.6464e-03,  2.9266e-03, -1.6460e-02,\n",
       "                       3.5323e-02,  2.4693e-02,  3.3591e-03, -2.6443e-02, -1.9645e-02,\n",
       "                      -8.1150e-03, -2.2893e-02, -3.3143e-02, -2.1016e-02,  2.5776e-02,\n",
       "                       1.4695e-02,  2.6393e-02, -3.7075e-02, -2.6075e-02,  1.7563e-02,\n",
       "                      -4.2136e-03,  2.7070e-02,  3.5387e-02,  2.7185e-02,  1.0113e-02,\n",
       "                      -1.2043e-02,  2.1303e-03,  1.6472e-02, -9.2460e-03, -2.7916e-02,\n",
       "                       2.2818e-02, -2.0333e-02,  2.4057e-02, -2.7549e-02, -3.1657e-02,\n",
       "                      -3.3777e-02,  3.4735e-02,  2.1888e-02,  4.5835e-03, -1.4555e-02,\n",
       "                       2.0063e-02,  1.4195e-02, -3.1953e-02, -2.0074e-02, -3.2204e-02,\n",
       "                       3.5814e-03,  1.0501e-03, -3.1710e-02,  1.1809e-04, -1.2138e-02,\n",
       "                       4.9693e-03,  3.7365e-02,  1.5454e-02, -1.5525e-02,  3.6330e-02,\n",
       "                       2.3244e-02, -4.1283e-03, -2.1559e-02, -3.5393e-02,  2.5753e-02,\n",
       "                      -2.7650e-02,  1.0564e-02, -2.0633e-03, -6.2235e-03, -3.3378e-02,\n",
       "                       7.0940e-03, -1.3188e-02,  1.9582e-02, -1.6225e-02, -4.0062e-03,\n",
       "                       2.8845e-02, -3.5654e-02,  3.6854e-02,  2.3743e-02, -7.5795e-03,\n",
       "                      -6.5061e-03,  5.2420e-03, -9.8629e-03,  1.8867e-03,  1.2842e-02,\n",
       "                       2.0273e-02,  2.9381e-02, -2.1800e-02,  2.3518e-02, -1.2788e-02,\n",
       "                      -8.8235e-03,  2.3487e-02, -1.6156e-02,  2.9464e-02, -2.0152e-02,\n",
       "                      -1.6385e-02,  1.7309e-02, -3.4159e-02,  1.2881e-02, -1.2914e-02,\n",
       "                       3.5814e-02,  1.9460e-02, -1.6026e-03,  2.1766e-02, -2.9959e-02,\n",
       "                       1.1944e-02, -2.0444e-03, -2.5963e-02, -2.9175e-03,  1.7178e-02,\n",
       "                      -3.7437e-02,  1.4013e-02, -1.9431e-02,  2.4797e-02,  3.2882e-02,\n",
       "                      -1.5557e-02,  5.5834e-03,  6.1212e-03, -1.0898e-02, -6.3031e-04,\n",
       "                       1.5165e-02,  8.0358e-04,  1.6443e-02,  1.5373e-02, -3.5048e-02,\n",
       "                       1.1353e-02, -1.7312e-02, -9.6346e-03,  8.1589e-05,  2.1654e-02,\n",
       "                       1.6522e-02,  1.1351e-02,  1.9483e-03, -2.2803e-03,  9.6486e-03,\n",
       "                      -2.5567e-02,  2.5884e-02,  1.2207e-02, -2.0659e-02,  2.3572e-02,\n",
       "                      -2.5166e-02,  1.5677e-02,  3.7770e-02,  5.6717e-03,  1.9296e-02,\n",
       "                       4.2178e-03, -1.7280e-02, -2.4301e-02,  5.6029e-03,  9.9075e-03,\n",
       "                      -2.1839e-02,  2.2465e-02, -2.8607e-03, -2.4094e-03,  1.0808e-02,\n",
       "                      -3.0449e-02,  1.4691e-04,  2.5994e-02,  7.2080e-03,  3.1278e-02,\n",
       "                      -1.4041e-02,  3.6271e-03,  2.3577e-02, -7.1508e-03, -1.3292e-02,\n",
       "                      -3.0473e-02,  6.3020e-03,  6.1840e-03, -1.6955e-02,  1.8431e-02,\n",
       "                      -2.0077e-02,  2.8111e-02,  3.8735e-03, -1.2408e-03, -2.8795e-02,\n",
       "                       1.0390e-02, -1.8146e-02, -3.0289e-02, -2.1248e-02,  7.3034e-03,\n",
       "                      -1.7861e-02, -2.0177e-02, -7.9841e-03,  3.4977e-02,  2.5351e-02,\n",
       "                       7.8891e-04,  2.6979e-02,  2.9477e-02,  1.9782e-02, -3.9929e-03,\n",
       "                      -2.7585e-02, -1.0834e-03,  1.8859e-02, -1.0468e-02, -2.0693e-02,\n",
       "                      -2.0113e-02, -3.3588e-02, -2.4661e-02, -1.9052e-02, -1.0504e-03,\n",
       "                      -3.0458e-04,  1.4694e-02,  2.0873e-02, -2.3765e-02, -2.5492e-02,\n",
       "                      -3.2437e-02, -3.2428e-03,  2.5040e-03,  1.7903e-02,  9.6098e-03,\n",
       "                       1.5131e-02, -3.0878e-02,  7.7369e-03,  1.3679e-02,  2.2921e-02,\n",
       "                      -1.8897e-02, -3.3062e-03,  2.1512e-02, -8.4554e-03, -2.7257e-02,\n",
       "                      -1.7414e-03,  2.5283e-02,  3.5004e-02,  3.0633e-02,  1.5544e-02,\n",
       "                       2.2377e-02, -4.3818e-03, -2.6145e-02,  1.5190e-02,  2.2536e-03,\n",
       "                       8.4437e-03, -1.4028e-02, -2.9536e-02, -3.8569e-03, -3.2770e-02,\n",
       "                       9.3304e-03, -3.6596e-02,  4.9614e-03,  4.6834e-03,  3.0568e-02,\n",
       "                       2.4537e-02, -1.3314e-02, -3.7748e-02,  2.0298e-03, -7.3051e-04,\n",
       "                      -2.3027e-02, -2.5354e-02,  1.1625e-02, -3.7050e-02,  5.9533e-03,\n",
       "                      -5.9811e-03, -2.0758e-02, -1.9196e-02,  1.2224e-02, -1.0941e-02,\n",
       "                      -3.0791e-03,  1.6975e-02,  1.4312e-02, -1.7058e-03,  2.5583e-02,\n",
       "                      -1.3548e-02,  2.8065e-02, -2.4338e-02,  2.5354e-02,  2.4403e-02,\n",
       "                       2.3824e-02, -3.7312e-02, -2.4642e-02, -2.2840e-02,  5.4863e-03,\n",
       "                      -2.7375e-02,  1.7714e-02,  1.1925e-02, -1.2807e-02, -3.6041e-02,\n",
       "                      -1.0886e-02,  1.4045e-02,  3.4877e-02, -4.7550e-03,  2.1108e-02,\n",
       "                      -1.4831e-02, -1.9791e-02, -1.6796e-02,  2.1588e-02,  1.8988e-02,\n",
       "                      -2.2777e-02, -1.9215e-02,  1.2088e-02,  3.3492e-02,  5.2212e-03,\n",
       "                      -3.4110e-03, -1.7846e-02,  2.3703e-02,  1.6383e-02,  1.2580e-02,\n",
       "                       1.4622e-02,  1.1441e-03,  2.4278e-02,  1.7289e-02,  3.1487e-02,\n",
       "                       8.6100e-03,  1.9806e-02, -2.0535e-02, -9.2880e-03, -1.9869e-03,\n",
       "                      -2.8474e-02, -2.0860e-02, -2.3962e-02,  2.0568e-02, -1.0669e-02,\n",
       "                      -7.4777e-03,  2.1776e-02, -3.4434e-02,  2.6616e-02,  2.4567e-02,\n",
       "                      -2.5793e-02,  2.0102e-02, -1.1307e-03, -1.3128e-02, -9.7070e-03,\n",
       "                       1.2548e-02, -3.4491e-02,  1.8203e-02,  3.5655e-02,  1.0726e-02,\n",
       "                       2.6237e-02,  2.8553e-02, -2.9595e-02, -6.3798e-03, -2.9269e-02,\n",
       "                       2.1378e-02,  6.9228e-03, -2.6589e-02, -2.5806e-02, -2.5673e-02,\n",
       "                       1.5189e-02,  2.1111e-02,  1.5776e-02,  1.8792e-02, -2.6565e-03,\n",
       "                      -4.4625e-04, -1.9235e-02,  3.3108e-02, -3.6888e-02,  3.0708e-03,\n",
       "                       1.2239e-02, -2.4981e-02, -1.4447e-02, -9.0214e-03,  1.7646e-02,\n",
       "                      -2.4630e-02,  9.8606e-03,  3.0057e-02,  3.6841e-02,  2.2315e-02,\n",
       "                       1.6385e-02,  4.2118e-03,  1.9146e-02,  2.2059e-02,  1.8144e-02,\n",
       "                      -2.9473e-03,  2.5274e-02,  5.1428e-03,  1.8131e-02,  3.1874e-03,\n",
       "                       2.1597e-02,  3.5195e-02,  1.5433e-03,  1.1091e-02,  7.2222e-03,\n",
       "                      -2.9119e-02, -2.2546e-02, -2.1124e-02,  2.9378e-02,  9.7948e-03,\n",
       "                      -1.6006e-02, -2.1308e-02,  3.5734e-02,  1.6251e-02, -1.6977e-02,\n",
       "                       2.0019e-02,  1.1105e-02,  2.7643e-02, -2.7027e-02,  2.8350e-02,\n",
       "                      -1.0314e-02,  1.4091e-02, -3.6059e-02,  3.0883e-02,  9.5386e-03,\n",
       "                      -1.8149e-02,  1.4066e-02,  2.8141e-02, -1.4700e-02,  2.2671e-02,\n",
       "                       1.7108e-02, -2.9943e-02,  3.2694e-02, -2.1795e-02,  5.5886e-04,\n",
       "                      -4.5157e-03, -5.8365e-03, -2.0803e-02,  3.8681e-03,  3.4405e-02,\n",
       "                       2.0448e-02, -2.7468e-02, -2.4482e-02,  1.9683e-02, -9.3086e-04,\n",
       "                      -2.5421e-02,  3.2681e-02,  1.4327e-02, -1.5231e-02,  1.9761e-03,\n",
       "                       1.0300e-03,  2.2939e-02, -1.9479e-02, -5.2880e-03,  6.3539e-03,\n",
       "                       1.2996e-02, -3.1024e-02,  3.3322e-02, -6.7613e-03, -1.5153e-02,\n",
       "                       8.0522e-03,  1.5013e-02, -1.4091e-02, -9.8584e-03, -2.2063e-02,\n",
       "                      -2.0716e-02, -3.3301e-02, -6.2972e-03, -3.5849e-03,  1.9089e-02,\n",
       "                       2.7014e-02,  2.2307e-02, -1.5951e-02,  4.0382e-03, -1.0395e-02])),\n",
       "             ('linear3.weight',\n",
       "              tensor([[ 0.0364,  0.0125,  0.0303,  ..., -0.0152,  0.0165,  0.0412],\n",
       "                      [ 0.0365,  0.0436, -0.0335,  ..., -0.0119, -0.0079,  0.0179],\n",
       "                      [ 0.0317,  0.0218,  0.0327,  ...,  0.0271,  0.0371,  0.0022],\n",
       "                      ...,\n",
       "                      [-0.0434, -0.0201, -0.0251,  ...,  0.0089,  0.0085, -0.0418],\n",
       "                      [-0.0179, -0.0388, -0.0376,  ...,  0.0295,  0.0065,  0.0385],\n",
       "                      [-0.0079,  0.0295, -0.0075,  ..., -0.0379, -0.0097, -0.0432]])),\n",
       "             ('linear3.bias',\n",
       "              tensor([-0.0411,  0.0034,  0.0043,  0.0268, -0.0413, -0.0385,  0.0368,  0.0144,\n",
       "                       0.0273,  0.0406])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[ 0.0191, -0.0220, -0.0336,  ...,  0.0182,  0.0270,  0.0173],\n",
       "                      [ 0.0439, -0.0374, -0.0326,  ...,  0.0143,  0.0408, -0.0415],\n",
       "                      [ 0.0311, -0.0192, -0.0134,  ..., -0.0433,  0.0268, -0.0013],\n",
       "                      ...,\n",
       "                      [-0.0321, -0.0009, -0.0157,  ..., -0.0287, -0.0142, -0.0261],\n",
       "                      [-0.0166,  0.0128, -0.0445,  ..., -0.0249,  0.0144,  0.0037],\n",
       "                      [ 0.0350, -0.0356, -0.0355,  ...,  0.0258, -0.0251,  0.0287]])),\n",
       "             ('linear2.bias',\n",
       "              tensor([-0.0302,  0.0064,  0.0015, -0.0277,  0.0123, -0.0187,  0.0425,  0.0115,\n",
       "                      -0.0407, -0.0282, -0.0068,  0.0140,  0.0141,  0.0065,  0.0239, -0.0296,\n",
       "                      -0.0128,  0.0384,  0.0327, -0.0405,  0.0050, -0.0186, -0.0102, -0.0030,\n",
       "                      -0.0250, -0.0393, -0.0030, -0.0401,  0.0092, -0.0024, -0.0374, -0.0443,\n",
       "                      -0.0041,  0.0353,  0.0404, -0.0224,  0.0263,  0.0121,  0.0405,  0.0034,\n",
       "                      -0.0417, -0.0043,  0.0057,  0.0095,  0.0136,  0.0081, -0.0018,  0.0397,\n",
       "                       0.0128, -0.0288, -0.0311, -0.0070, -0.0286,  0.0114, -0.0438,  0.0180,\n",
       "                      -0.0091, -0.0161, -0.0398,  0.0128,  0.0405,  0.0412,  0.0146, -0.0282,\n",
       "                       0.0136, -0.0345, -0.0032, -0.0028, -0.0242,  0.0349, -0.0321, -0.0123,\n",
       "                      -0.0364, -0.0121,  0.0286,  0.0315, -0.0132,  0.0062,  0.0119, -0.0024,\n",
       "                       0.0392,  0.0005, -0.0388, -0.0098, -0.0100,  0.0024,  0.0021, -0.0081,\n",
       "                       0.0349,  0.0136, -0.0312, -0.0431, -0.0376, -0.0146, -0.0092, -0.0029,\n",
       "                      -0.0362, -0.0293, -0.0289, -0.0199,  0.0334,  0.0439,  0.0085,  0.0397,\n",
       "                       0.0186,  0.0248,  0.0264, -0.0434,  0.0029,  0.0415,  0.0442, -0.0080,\n",
       "                       0.0143,  0.0249,  0.0246, -0.0433,  0.0025, -0.0265,  0.0118, -0.0330,\n",
       "                       0.0383,  0.0270,  0.0339, -0.0192,  0.0231, -0.0376, -0.0128,  0.0268,\n",
       "                       0.0164, -0.0220, -0.0184, -0.0442, -0.0352, -0.0161,  0.0077,  0.0062,\n",
       "                      -0.0293, -0.0347,  0.0095, -0.0419,  0.0375,  0.0343, -0.0302,  0.0108,\n",
       "                       0.0212,  0.0429, -0.0412,  0.0420, -0.0212,  0.0141,  0.0010,  0.0324,\n",
       "                       0.0203, -0.0010, -0.0072,  0.0259, -0.0230,  0.0380,  0.0123, -0.0132,\n",
       "                       0.0121,  0.0361, -0.0009, -0.0252,  0.0199, -0.0351, -0.0389, -0.0040,\n",
       "                       0.0381,  0.0011, -0.0362,  0.0227, -0.0310,  0.0208,  0.0315, -0.0322,\n",
       "                      -0.0024,  0.0119,  0.0060, -0.0106,  0.0073, -0.0061,  0.0240, -0.0310,\n",
       "                      -0.0290,  0.0231,  0.0298,  0.0361, -0.0265,  0.0444,  0.0225, -0.0176,\n",
       "                      -0.0287, -0.0205, -0.0308,  0.0205,  0.0417, -0.0115,  0.0140, -0.0340,\n",
       "                      -0.0145,  0.0251,  0.0225,  0.0113,  0.0249,  0.0183,  0.0025,  0.0017,\n",
       "                       0.0128,  0.0407, -0.0064, -0.0306, -0.0052, -0.0337, -0.0182, -0.0407,\n",
       "                      -0.0231,  0.0353,  0.0220, -0.0219,  0.0088, -0.0006,  0.0052, -0.0371,\n",
       "                      -0.0343,  0.0200, -0.0138,  0.0009, -0.0048,  0.0275, -0.0318, -0.0423,\n",
       "                      -0.0414, -0.0266,  0.0077,  0.0369, -0.0065,  0.0238,  0.0085,  0.0173,\n",
       "                      -0.0239, -0.0126, -0.0274,  0.0201, -0.0276, -0.0101, -0.0369,  0.0139,\n",
       "                       0.0021,  0.0325,  0.0241, -0.0311,  0.0076,  0.0110, -0.0136, -0.0016,\n",
       "                      -0.0437,  0.0425,  0.0019, -0.0004, -0.0191, -0.0167, -0.0041, -0.0382,\n",
       "                      -0.0348,  0.0090,  0.0358,  0.0379,  0.0284, -0.0096,  0.0328,  0.0372,\n",
       "                       0.0028, -0.0318, -0.0124, -0.0049,  0.0426,  0.0193,  0.0180,  0.0142,\n",
       "                       0.0395,  0.0188, -0.0230, -0.0251,  0.0270,  0.0076,  0.0269,  0.0169,\n",
       "                       0.0396, -0.0399,  0.0249, -0.0375, -0.0170,  0.0293,  0.0083,  0.0164,\n",
       "                       0.0149,  0.0231, -0.0012, -0.0059, -0.0302,  0.0387, -0.0242,  0.0401,\n",
       "                       0.0174, -0.0096, -0.0441,  0.0205, -0.0111,  0.0233, -0.0397, -0.0146,\n",
       "                      -0.0125, -0.0228,  0.0203, -0.0193, -0.0294, -0.0122, -0.0181,  0.0363,\n",
       "                      -0.0181, -0.0046, -0.0179,  0.0014, -0.0157,  0.0073, -0.0080,  0.0300,\n",
       "                      -0.0110,  0.0136, -0.0437,  0.0208, -0.0153,  0.0151,  0.0212, -0.0189,\n",
       "                       0.0372,  0.0147,  0.0169, -0.0264, -0.0155, -0.0130,  0.0398,  0.0305,\n",
       "                      -0.0417, -0.0406, -0.0364, -0.0276, -0.0307,  0.0314,  0.0214,  0.0058,\n",
       "                      -0.0221, -0.0312,  0.0387, -0.0427, -0.0167, -0.0167, -0.0142,  0.0325,\n",
       "                      -0.0272, -0.0235, -0.0263,  0.0068, -0.0320, -0.0366, -0.0412,  0.0233,\n",
       "                       0.0294, -0.0236,  0.0260, -0.0236,  0.0017, -0.0156,  0.0108, -0.0406,\n",
       "                       0.0126,  0.0253,  0.0223,  0.0390,  0.0186,  0.0147,  0.0226, -0.0365,\n",
       "                      -0.0203, -0.0178,  0.0426,  0.0014,  0.0418, -0.0414,  0.0238, -0.0088,\n",
       "                      -0.0229,  0.0099,  0.0182, -0.0334,  0.0310,  0.0096, -0.0087,  0.0054,\n",
       "                      -0.0240, -0.0112, -0.0317, -0.0101, -0.0111,  0.0211, -0.0113, -0.0438,\n",
       "                       0.0043, -0.0212, -0.0036, -0.0070,  0.0273,  0.0447, -0.0233, -0.0156,\n",
       "                      -0.0136, -0.0248,  0.0312, -0.0362,  0.0295, -0.0011, -0.0097, -0.0196,\n",
       "                       0.0049, -0.0078, -0.0307, -0.0120,  0.0323,  0.0349, -0.0136,  0.0365,\n",
       "                      -0.0240, -0.0166,  0.0132,  0.0068, -0.0300, -0.0050, -0.0058,  0.0021,\n",
       "                       0.0203,  0.0234,  0.0127,  0.0052,  0.0090, -0.0187, -0.0196, -0.0188,\n",
       "                       0.0124,  0.0332, -0.0375,  0.0121,  0.0040,  0.0121, -0.0399, -0.0105,\n",
       "                      -0.0411, -0.0234,  0.0395,  0.0101,  0.0412, -0.0228,  0.0009, -0.0132,\n",
       "                      -0.0447,  0.0181,  0.0421,  0.0058, -0.0165, -0.0144, -0.0420,  0.0001,\n",
       "                      -0.0260, -0.0132,  0.0029, -0.0152, -0.0248, -0.0111,  0.0384, -0.0436,\n",
       "                       0.0175, -0.0316,  0.0353, -0.0352,  0.0445,  0.0198, -0.0282,  0.0402,\n",
       "                      -0.0230, -0.0408,  0.0255, -0.0080, -0.0199, -0.0414,  0.0306, -0.0275,\n",
       "                      -0.0085, -0.0179, -0.0235, -0.0102]))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[ 3.5266e-02,  5.7545e-03, -3.4416e-02,  ..., -2.6693e-02,\n",
       "                       -3.0254e-02, -5.2823e-03],\n",
       "                      [-4.8144e-03,  1.9251e-02, -1.7009e-02,  ..., -8.3402e-03,\n",
       "                       -3.5727e-02, -3.1722e-02],\n",
       "                      [ 2.5009e-02, -2.3408e-02, -2.4295e-02,  ..., -5.3888e-03,\n",
       "                        8.9848e-03,  3.1952e-02],\n",
       "                      ...,\n",
       "                      [ 3.3807e-02,  2.1817e-03,  8.7364e-03,  ..., -3.3118e-02,\n",
       "                       -7.7291e-05,  3.4851e-02],\n",
       "                      [ 1.2947e-02,  3.3807e-02, -3.7735e-02,  ...,  1.5305e-02,\n",
       "                        1.3197e-02, -1.5404e-02],\n",
       "                      [ 1.6492e-02, -1.9562e-02, -5.0703e-03,  ..., -2.2453e-02,\n",
       "                       -3.2365e-02,  1.2563e-02]])),\n",
       "             ('linear1.bias',\n",
       "              tensor([-8.9737e-03, -2.8011e-02, -1.7497e-02, -3.1679e-02, -1.2169e-02,\n",
       "                      -3.7304e-02,  8.6797e-04, -1.5913e-02, -5.3632e-03, -1.1712e-02,\n",
       "                       1.3446e-02, -3.5661e-02,  1.7712e-02, -3.4449e-02,  3.1551e-02,\n",
       "                      -5.8992e-03,  2.5977e-03, -2.6701e-02, -1.8009e-02,  2.2785e-02,\n",
       "                       3.0546e-02, -3.6360e-03, -1.9009e-02, -2.9282e-02, -1.5521e-02,\n",
       "                       4.4236e-03,  1.1506e-03, -3.2206e-02, -1.5879e-02,  3.0385e-02,\n",
       "                       2.7589e-02, -3.0279e-02, -2.3494e-03, -3.2146e-02,  3.2560e-02,\n",
       "                       2.7510e-02, -1.6275e-02,  2.4497e-02, -2.2980e-02, -3.1411e-02,\n",
       "                       1.8908e-02, -1.2419e-02, -2.9374e-02,  2.0183e-02, -2.7791e-03,\n",
       "                      -2.8611e-02, -3.4616e-02, -2.0105e-02, -1.3601e-02,  6.8507e-03,\n",
       "                       1.1241e-02, -2.8677e-02, -1.5932e-02, -3.3600e-03, -2.3516e-02,\n",
       "                       3.1179e-02, -3.2283e-03,  2.7280e-03, -1.6169e-02, -3.0204e-03,\n",
       "                       7.6628e-03,  8.4112e-03,  3.5963e-02,  3.4421e-02, -3.5557e-02,\n",
       "                      -3.0338e-02, -2.1013e-02, -9.6464e-03,  2.9266e-03, -1.6460e-02,\n",
       "                       3.5323e-02,  2.4693e-02,  3.3591e-03, -2.6443e-02, -1.9645e-02,\n",
       "                      -8.1150e-03, -2.2893e-02, -3.3143e-02, -2.1016e-02,  2.5776e-02,\n",
       "                       1.4695e-02,  2.6393e-02, -3.7075e-02, -2.6075e-02,  1.7563e-02,\n",
       "                      -4.2136e-03,  2.7070e-02,  3.5387e-02,  2.7185e-02,  1.0113e-02,\n",
       "                      -1.2043e-02,  2.1303e-03,  1.6472e-02, -9.2460e-03, -2.7916e-02,\n",
       "                       2.2818e-02, -2.0333e-02,  2.4057e-02, -2.7549e-02, -3.1657e-02,\n",
       "                      -3.3777e-02,  3.4735e-02,  2.1888e-02,  4.5835e-03, -1.4555e-02,\n",
       "                       2.0063e-02,  1.4195e-02, -3.1953e-02, -2.0074e-02, -3.2204e-02,\n",
       "                       3.5814e-03,  1.0501e-03, -3.1710e-02,  1.1809e-04, -1.2138e-02,\n",
       "                       4.9693e-03,  3.7365e-02,  1.5454e-02, -1.5525e-02,  3.6330e-02,\n",
       "                       2.3244e-02, -4.1283e-03, -2.1559e-02, -3.5393e-02,  2.5753e-02,\n",
       "                      -2.7650e-02,  1.0564e-02, -2.0633e-03, -6.2235e-03, -3.3378e-02,\n",
       "                       7.0940e-03, -1.3188e-02,  1.9582e-02, -1.6225e-02, -4.0062e-03,\n",
       "                       2.8845e-02, -3.5654e-02,  3.6854e-02,  2.3743e-02, -7.5795e-03,\n",
       "                      -6.5061e-03,  5.2420e-03, -9.8629e-03,  1.8867e-03,  1.2842e-02,\n",
       "                       2.0273e-02,  2.9381e-02, -2.1800e-02,  2.3518e-02, -1.2788e-02,\n",
       "                      -8.8235e-03,  2.3487e-02, -1.6156e-02,  2.9464e-02, -2.0152e-02,\n",
       "                      -1.6385e-02,  1.7309e-02, -3.4159e-02,  1.2881e-02, -1.2914e-02,\n",
       "                       3.5814e-02,  1.9460e-02, -1.6026e-03,  2.1766e-02, -2.9959e-02,\n",
       "                       1.1944e-02, -2.0444e-03, -2.5963e-02, -2.9175e-03,  1.7178e-02,\n",
       "                      -3.7437e-02,  1.4013e-02, -1.9431e-02,  2.4797e-02,  3.2882e-02,\n",
       "                      -1.5557e-02,  5.5834e-03,  6.1212e-03, -1.0898e-02, -6.3031e-04,\n",
       "                       1.5165e-02,  8.0358e-04,  1.6443e-02,  1.5373e-02, -3.5048e-02,\n",
       "                       1.1353e-02, -1.7312e-02, -9.6346e-03,  8.1589e-05,  2.1654e-02,\n",
       "                       1.6522e-02,  1.1351e-02,  1.9483e-03, -2.2803e-03,  9.6486e-03,\n",
       "                      -2.5567e-02,  2.5884e-02,  1.2207e-02, -2.0659e-02,  2.3572e-02,\n",
       "                      -2.5166e-02,  1.5677e-02,  3.7770e-02,  5.6717e-03,  1.9296e-02,\n",
       "                       4.2178e-03, -1.7280e-02, -2.4301e-02,  5.6029e-03,  9.9075e-03,\n",
       "                      -2.1839e-02,  2.2465e-02, -2.8607e-03, -2.4094e-03,  1.0808e-02,\n",
       "                      -3.0449e-02,  1.4691e-04,  2.5994e-02,  7.2080e-03,  3.1278e-02,\n",
       "                      -1.4041e-02,  3.6271e-03,  2.3577e-02, -7.1508e-03, -1.3292e-02,\n",
       "                      -3.0473e-02,  6.3020e-03,  6.1840e-03, -1.6955e-02,  1.8431e-02,\n",
       "                      -2.0077e-02,  2.8111e-02,  3.8735e-03, -1.2408e-03, -2.8795e-02,\n",
       "                       1.0390e-02, -1.8146e-02, -3.0289e-02, -2.1248e-02,  7.3034e-03,\n",
       "                      -1.7861e-02, -2.0177e-02, -7.9841e-03,  3.4977e-02,  2.5351e-02,\n",
       "                       7.8891e-04,  2.6979e-02,  2.9477e-02,  1.9782e-02, -3.9929e-03,\n",
       "                      -2.7585e-02, -1.0834e-03,  1.8859e-02, -1.0468e-02, -2.0693e-02,\n",
       "                      -2.0113e-02, -3.3588e-02, -2.4661e-02, -1.9052e-02, -1.0504e-03,\n",
       "                      -3.0458e-04,  1.4694e-02,  2.0873e-02, -2.3765e-02, -2.5492e-02,\n",
       "                      -3.2437e-02, -3.2428e-03,  2.5040e-03,  1.7903e-02,  9.6098e-03,\n",
       "                       1.5131e-02, -3.0878e-02,  7.7369e-03,  1.3679e-02,  2.2921e-02,\n",
       "                      -1.8897e-02, -3.3062e-03,  2.1512e-02, -8.4554e-03, -2.7257e-02,\n",
       "                      -1.7414e-03,  2.5283e-02,  3.5004e-02,  3.0633e-02,  1.5544e-02,\n",
       "                       2.2377e-02, -4.3818e-03, -2.6145e-02,  1.5190e-02,  2.2536e-03,\n",
       "                       8.4437e-03, -1.4028e-02, -2.9536e-02, -3.8569e-03, -3.2770e-02,\n",
       "                       9.3304e-03, -3.6596e-02,  4.9614e-03,  4.6834e-03,  3.0568e-02,\n",
       "                       2.4537e-02, -1.3314e-02, -3.7748e-02,  2.0298e-03, -7.3051e-04,\n",
       "                      -2.3027e-02, -2.5354e-02,  1.1625e-02, -3.7050e-02,  5.9533e-03,\n",
       "                      -5.9811e-03, -2.0758e-02, -1.9196e-02,  1.2224e-02, -1.0941e-02,\n",
       "                      -3.0791e-03,  1.6975e-02,  1.4312e-02, -1.7058e-03,  2.5583e-02,\n",
       "                      -1.3548e-02,  2.8065e-02, -2.4338e-02,  2.5354e-02,  2.4403e-02,\n",
       "                       2.3824e-02, -3.7312e-02, -2.4642e-02, -2.2840e-02,  5.4863e-03,\n",
       "                      -2.7375e-02,  1.7714e-02,  1.1925e-02, -1.2807e-02, -3.6041e-02,\n",
       "                      -1.0886e-02,  1.4045e-02,  3.4877e-02, -4.7550e-03,  2.1108e-02,\n",
       "                      -1.4831e-02, -1.9791e-02, -1.6796e-02,  2.1588e-02,  1.8988e-02,\n",
       "                      -2.2777e-02, -1.9215e-02,  1.2088e-02,  3.3492e-02,  5.2212e-03,\n",
       "                      -3.4110e-03, -1.7846e-02,  2.3703e-02,  1.6383e-02,  1.2580e-02,\n",
       "                       1.4622e-02,  1.1441e-03,  2.4278e-02,  1.7289e-02,  3.1487e-02,\n",
       "                       8.6100e-03,  1.9806e-02, -2.0535e-02, -9.2880e-03, -1.9869e-03,\n",
       "                      -2.8474e-02, -2.0860e-02, -2.3962e-02,  2.0568e-02, -1.0669e-02,\n",
       "                      -7.4777e-03,  2.1776e-02, -3.4434e-02,  2.6616e-02,  2.4567e-02,\n",
       "                      -2.5793e-02,  2.0102e-02, -1.1307e-03, -1.3128e-02, -9.7070e-03,\n",
       "                       1.2548e-02, -3.4491e-02,  1.8203e-02,  3.5655e-02,  1.0726e-02,\n",
       "                       2.6237e-02,  2.8553e-02, -2.9595e-02, -6.3798e-03, -2.9269e-02,\n",
       "                       2.1378e-02,  6.9228e-03, -2.6589e-02, -2.5806e-02, -2.5673e-02,\n",
       "                       1.5189e-02,  2.1111e-02,  1.5776e-02,  1.8792e-02, -2.6565e-03,\n",
       "                      -4.4625e-04, -1.9235e-02,  3.3108e-02, -3.6888e-02,  3.0708e-03,\n",
       "                       1.2239e-02, -2.4981e-02, -1.4447e-02, -9.0214e-03,  1.7646e-02,\n",
       "                      -2.4630e-02,  9.8606e-03,  3.0057e-02,  3.6841e-02,  2.2315e-02,\n",
       "                       1.6385e-02,  4.2118e-03,  1.9146e-02,  2.2059e-02,  1.8144e-02,\n",
       "                      -2.9473e-03,  2.5274e-02,  5.1428e-03,  1.8131e-02,  3.1874e-03,\n",
       "                       2.1597e-02,  3.5195e-02,  1.5433e-03,  1.1091e-02,  7.2222e-03,\n",
       "                      -2.9119e-02, -2.2546e-02, -2.1124e-02,  2.9378e-02,  9.7948e-03,\n",
       "                      -1.6006e-02, -2.1308e-02,  3.5734e-02,  1.6251e-02, -1.6977e-02,\n",
       "                       2.0019e-02,  1.1105e-02,  2.7643e-02, -2.7027e-02,  2.8350e-02,\n",
       "                      -1.0314e-02,  1.4091e-02, -3.6059e-02,  3.0883e-02,  9.5386e-03,\n",
       "                      -1.8149e-02,  1.4066e-02,  2.8141e-02, -1.4700e-02,  2.2671e-02,\n",
       "                       1.7108e-02, -2.9943e-02,  3.2694e-02, -2.1795e-02,  5.5886e-04,\n",
       "                      -4.5157e-03, -5.8365e-03, -2.0803e-02,  3.8681e-03,  3.4405e-02,\n",
       "                       2.0448e-02, -2.7468e-02, -2.4482e-02,  1.9683e-02, -9.3086e-04,\n",
       "                      -2.5421e-02,  3.2681e-02,  1.4327e-02, -1.5231e-02,  1.9761e-03,\n",
       "                       1.0300e-03,  2.2939e-02, -1.9479e-02, -5.2880e-03,  6.3539e-03,\n",
       "                       1.2996e-02, -3.1024e-02,  3.3322e-02, -6.7613e-03, -1.5153e-02,\n",
       "                       8.0522e-03,  1.5013e-02, -1.4091e-02, -9.8584e-03, -2.2063e-02,\n",
       "                      -2.0716e-02, -3.3301e-02, -6.2972e-03, -3.5849e-03,  1.9089e-02,\n",
       "                       2.7014e-02,  2.2307e-02, -1.5951e-02,  4.0382e-03, -1.0395e-02])),\n",
       "             ('linear3.weight',\n",
       "              tensor([[ 0.0364,  0.0125,  0.0303,  ..., -0.0152,  0.0165,  0.0412],\n",
       "                      [ 0.0365,  0.0436, -0.0335,  ..., -0.0119, -0.0079,  0.0179],\n",
       "                      [ 0.0317,  0.0218,  0.0327,  ...,  0.0271,  0.0371,  0.0022],\n",
       "                      ...,\n",
       "                      [-0.0434, -0.0201, -0.0251,  ...,  0.0089,  0.0085, -0.0418],\n",
       "                      [-0.0179, -0.0388, -0.0376,  ...,  0.0295,  0.0065,  0.0385],\n",
       "                      [-0.0079,  0.0295, -0.0075,  ..., -0.0379, -0.0097, -0.0432]])),\n",
       "             ('linear3.bias',\n",
       "              tensor([-0.0411,  0.0034,  0.0043,  0.0268, -0.0413, -0.0385,  0.0368,  0.0144,\n",
       "                       0.0273,  0.0406])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[ 0.0191, -0.0220, -0.0336,  ...,  0.0182,  0.0270,  0.0173],\n",
       "                      [ 0.0439, -0.0374, -0.0326,  ...,  0.0143,  0.0408, -0.0415],\n",
       "                      [ 0.0311, -0.0192, -0.0134,  ..., -0.0433,  0.0268, -0.0013],\n",
       "                      ...,\n",
       "                      [-0.0321, -0.0009, -0.0157,  ..., -0.0287, -0.0142, -0.0261],\n",
       "                      [-0.0166,  0.0128, -0.0445,  ..., -0.0249,  0.0144,  0.0037],\n",
       "                      [ 0.0350, -0.0356, -0.0355,  ...,  0.0258, -0.0251,  0.0287]])),\n",
       "             ('linear2.bias',\n",
       "              tensor([-0.0302,  0.0064,  0.0015, -0.0277,  0.0123, -0.0187,  0.0425,  0.0115,\n",
       "                      -0.0407, -0.0282, -0.0068,  0.0140,  0.0141,  0.0065,  0.0239, -0.0296,\n",
       "                      -0.0128,  0.0384,  0.0327, -0.0405,  0.0050, -0.0186, -0.0102, -0.0030,\n",
       "                      -0.0250, -0.0393, -0.0030, -0.0401,  0.0092, -0.0024, -0.0374, -0.0443,\n",
       "                      -0.0041,  0.0353,  0.0404, -0.0224,  0.0263,  0.0121,  0.0405,  0.0034,\n",
       "                      -0.0417, -0.0043,  0.0057,  0.0095,  0.0136,  0.0081, -0.0018,  0.0397,\n",
       "                       0.0128, -0.0288, -0.0311, -0.0070, -0.0286,  0.0114, -0.0438,  0.0180,\n",
       "                      -0.0091, -0.0161, -0.0398,  0.0128,  0.0405,  0.0412,  0.0146, -0.0282,\n",
       "                       0.0136, -0.0345, -0.0032, -0.0028, -0.0242,  0.0349, -0.0321, -0.0123,\n",
       "                      -0.0364, -0.0121,  0.0286,  0.0315, -0.0132,  0.0062,  0.0119, -0.0024,\n",
       "                       0.0392,  0.0005, -0.0388, -0.0098, -0.0100,  0.0024,  0.0021, -0.0081,\n",
       "                       0.0349,  0.0136, -0.0312, -0.0431, -0.0376, -0.0146, -0.0092, -0.0029,\n",
       "                      -0.0362, -0.0293, -0.0289, -0.0199,  0.0334,  0.0439,  0.0085,  0.0397,\n",
       "                       0.0186,  0.0248,  0.0264, -0.0434,  0.0029,  0.0415,  0.0442, -0.0080,\n",
       "                       0.0143,  0.0249,  0.0246, -0.0433,  0.0025, -0.0265,  0.0118, -0.0330,\n",
       "                       0.0383,  0.0270,  0.0339, -0.0192,  0.0231, -0.0376, -0.0128,  0.0268,\n",
       "                       0.0164, -0.0220, -0.0184, -0.0442, -0.0352, -0.0161,  0.0077,  0.0062,\n",
       "                      -0.0293, -0.0347,  0.0095, -0.0419,  0.0375,  0.0343, -0.0302,  0.0108,\n",
       "                       0.0212,  0.0429, -0.0412,  0.0420, -0.0212,  0.0141,  0.0010,  0.0324,\n",
       "                       0.0203, -0.0010, -0.0072,  0.0259, -0.0230,  0.0380,  0.0123, -0.0132,\n",
       "                       0.0121,  0.0361, -0.0009, -0.0252,  0.0199, -0.0351, -0.0389, -0.0040,\n",
       "                       0.0381,  0.0011, -0.0362,  0.0227, -0.0310,  0.0208,  0.0315, -0.0322,\n",
       "                      -0.0024,  0.0119,  0.0060, -0.0106,  0.0073, -0.0061,  0.0240, -0.0310,\n",
       "                      -0.0290,  0.0231,  0.0298,  0.0361, -0.0265,  0.0444,  0.0225, -0.0176,\n",
       "                      -0.0287, -0.0205, -0.0308,  0.0205,  0.0417, -0.0115,  0.0140, -0.0340,\n",
       "                      -0.0145,  0.0251,  0.0225,  0.0113,  0.0249,  0.0183,  0.0025,  0.0017,\n",
       "                       0.0128,  0.0407, -0.0064, -0.0306, -0.0052, -0.0337, -0.0182, -0.0407,\n",
       "                      -0.0231,  0.0353,  0.0220, -0.0219,  0.0088, -0.0006,  0.0052, -0.0371,\n",
       "                      -0.0343,  0.0200, -0.0138,  0.0009, -0.0048,  0.0275, -0.0318, -0.0423,\n",
       "                      -0.0414, -0.0266,  0.0077,  0.0369, -0.0065,  0.0238,  0.0085,  0.0173,\n",
       "                      -0.0239, -0.0126, -0.0274,  0.0201, -0.0276, -0.0101, -0.0369,  0.0139,\n",
       "                       0.0021,  0.0325,  0.0241, -0.0311,  0.0076,  0.0110, -0.0136, -0.0016,\n",
       "                      -0.0437,  0.0425,  0.0019, -0.0004, -0.0191, -0.0167, -0.0041, -0.0382,\n",
       "                      -0.0348,  0.0090,  0.0358,  0.0379,  0.0284, -0.0096,  0.0328,  0.0372,\n",
       "                       0.0028, -0.0318, -0.0124, -0.0049,  0.0426,  0.0193,  0.0180,  0.0142,\n",
       "                       0.0395,  0.0188, -0.0230, -0.0251,  0.0270,  0.0076,  0.0269,  0.0169,\n",
       "                       0.0396, -0.0399,  0.0249, -0.0375, -0.0170,  0.0293,  0.0083,  0.0164,\n",
       "                       0.0149,  0.0231, -0.0012, -0.0059, -0.0302,  0.0387, -0.0242,  0.0401,\n",
       "                       0.0174, -0.0096, -0.0441,  0.0205, -0.0111,  0.0233, -0.0397, -0.0146,\n",
       "                      -0.0125, -0.0228,  0.0203, -0.0193, -0.0294, -0.0122, -0.0181,  0.0363,\n",
       "                      -0.0181, -0.0046, -0.0179,  0.0014, -0.0157,  0.0073, -0.0080,  0.0300,\n",
       "                      -0.0110,  0.0136, -0.0437,  0.0208, -0.0153,  0.0151,  0.0212, -0.0189,\n",
       "                       0.0372,  0.0147,  0.0169, -0.0264, -0.0155, -0.0130,  0.0398,  0.0305,\n",
       "                      -0.0417, -0.0406, -0.0364, -0.0276, -0.0307,  0.0314,  0.0214,  0.0058,\n",
       "                      -0.0221, -0.0312,  0.0387, -0.0427, -0.0167, -0.0167, -0.0142,  0.0325,\n",
       "                      -0.0272, -0.0235, -0.0263,  0.0068, -0.0320, -0.0366, -0.0412,  0.0233,\n",
       "                       0.0294, -0.0236,  0.0260, -0.0236,  0.0017, -0.0156,  0.0108, -0.0406,\n",
       "                       0.0126,  0.0253,  0.0223,  0.0390,  0.0186,  0.0147,  0.0226, -0.0365,\n",
       "                      -0.0203, -0.0178,  0.0426,  0.0014,  0.0418, -0.0414,  0.0238, -0.0088,\n",
       "                      -0.0229,  0.0099,  0.0182, -0.0334,  0.0310,  0.0096, -0.0087,  0.0054,\n",
       "                      -0.0240, -0.0112, -0.0317, -0.0101, -0.0111,  0.0211, -0.0113, -0.0438,\n",
       "                       0.0043, -0.0212, -0.0036, -0.0070,  0.0273,  0.0447, -0.0233, -0.0156,\n",
       "                      -0.0136, -0.0248,  0.0312, -0.0362,  0.0295, -0.0011, -0.0097, -0.0196,\n",
       "                       0.0049, -0.0078, -0.0307, -0.0120,  0.0323,  0.0349, -0.0136,  0.0365,\n",
       "                      -0.0240, -0.0166,  0.0132,  0.0068, -0.0300, -0.0050, -0.0058,  0.0021,\n",
       "                       0.0203,  0.0234,  0.0127,  0.0052,  0.0090, -0.0187, -0.0196, -0.0188,\n",
       "                       0.0124,  0.0332, -0.0375,  0.0121,  0.0040,  0.0121, -0.0399, -0.0105,\n",
       "                      -0.0411, -0.0234,  0.0395,  0.0101,  0.0412, -0.0228,  0.0009, -0.0132,\n",
       "                      -0.0447,  0.0181,  0.0421,  0.0058, -0.0165, -0.0144, -0.0420,  0.0001,\n",
       "                      -0.0260, -0.0132,  0.0029, -0.0152, -0.0248, -0.0111,  0.0384, -0.0436,\n",
       "                       0.0175, -0.0316,  0.0353, -0.0352,  0.0445,  0.0198, -0.0282,  0.0402,\n",
       "                      -0.0230, -0.0408,  0.0255, -0.0080, -0.0199, -0.0414,  0.0306, -0.0275,\n",
       "                      -0.0085, -0.0179, -0.0235, -0.0102]))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Оптимизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.optim.sgd.SGD, torch.optim.adam.Adam)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.SGD, optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), betas=(0.9, 0.999), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "    [\n",
    "        {'params': net.linear1.parameters()},\n",
    "        {'params': net.linear2.parameters(), 'lr': 1e-3}\n",
    "    ],\n",
    "    lr=1e-2,\n",
    "    momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.nn.modules.loss.L1Loss,\n",
       " torch.nn.modules.loss.MSELoss,\n",
       " torch.nn.modules.loss.CrossEntropyLoss)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.L1Loss, nn.MSELoss, nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2666, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "\n",
    "output = loss(x, target)\n",
    "\n",
    "print(output)\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0048,  0.0302, -0.1696,  0.0088, -0.1233],\n",
       "        [-0.0516, -0.1192, -0.0600,  0.1681, -0.0162],\n",
       "        [ 0.0931, -0.4144,  0.0005,  0.0449, -0.2476]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Датасеты и даталоадеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "n_objects = 300\n",
    "\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300, 2]), torch.Size([300, 1]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_true = torch.randn(n_features)\n",
    "\n",
    "X = (torch.rand(n_objects, n_features) - 0.5) * 10\n",
    "X *= (torch.arange(n_features) * 2 + 1)\n",
    "Y = (X @ w_true + torch.randn(n_objects)).unsqueeze(1)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9258e+00,  4.0224e+00],\n",
       "        [-9.9066e-02,  1.1893e+01],\n",
       "        [-4.4372e-01,  3.9692e+00],\n",
       "        [-1.5111e+00, -2.9485e+00],\n",
       "        [-4.7767e+00, -9.9342e+00],\n",
       "        [-2.0611e+00,  5.5565e-01],\n",
       "        [ 1.9767e+00,  9.0003e+00],\n",
       "        [-3.3897e+00, -6.5319e+00],\n",
       "        [ 1.8161e+00,  1.2456e+01],\n",
       "        [-1.0290e+00,  1.1225e+01],\n",
       "        [-8.0592e-01,  1.5872e+00],\n",
       "        [ 4.5274e+00, -1.3915e+01],\n",
       "        [-3.1477e+00, -3.7975e+00],\n",
       "        [-1.9490e+00,  1.2960e+01],\n",
       "        [-3.2409e+00, -6.9050e+00],\n",
       "        [-3.4932e+00, -1.4048e+01],\n",
       "        [-2.9187e+00,  1.2894e+01],\n",
       "        [ 2.2311e+00,  7.2701e+00],\n",
       "        [ 2.6296e-01, -7.6903e+00],\n",
       "        [ 8.4592e-01, -1.4005e+01],\n",
       "        [-3.6128e+00, -7.7330e+00],\n",
       "        [ 3.1547e+00,  8.7948e+00],\n",
       "        [-2.2175e+00, -5.4124e-01],\n",
       "        [ 3.1978e+00,  1.4912e+01],\n",
       "        [ 1.9844e+00,  2.0264e+00],\n",
       "        [ 3.3524e+00, -8.8320e+00],\n",
       "        [ 9.3172e-01, -1.1630e+01],\n",
       "        [-3.4654e+00, -7.7488e+00],\n",
       "        [ 2.2624e+00,  6.0324e+00],\n",
       "        [-2.9618e+00,  4.5316e+00],\n",
       "        [ 2.7449e+00, -1.8933e+00],\n",
       "        [ 1.9091e-01,  3.4756e+00],\n",
       "        [ 3.1019e+00,  1.4403e+01],\n",
       "        [-3.8531e+00, -5.4970e+00],\n",
       "        [ 1.9650e+00,  1.2428e+01],\n",
       "        [ 4.3510e+00,  1.3235e+01],\n",
       "        [ 9.9507e-01, -1.3044e+01],\n",
       "        [ 4.5996e-01, -9.3841e+00],\n",
       "        [-4.6598e+00,  1.3327e+01],\n",
       "        [ 3.8018e+00, -1.4963e+01],\n",
       "        [ 9.3586e-01, -2.5269e+00],\n",
       "        [-8.2281e-01, -6.8664e+00],\n",
       "        [ 1.9228e+00, -8.8846e+00],\n",
       "        [ 1.8330e+00,  7.5856e+00],\n",
       "        [ 3.5794e+00,  5.6087e+00],\n",
       "        [-4.9487e+00, -9.7305e+00],\n",
       "        [ 2.4966e+00,  3.1395e+00],\n",
       "        [-3.9004e+00, -8.6373e+00],\n",
       "        [ 4.7037e+00,  1.0107e+01],\n",
       "        [-2.1801e+00, -3.7753e+00],\n",
       "        [-4.7630e+00, -2.6961e-01],\n",
       "        [-3.7653e+00, -1.1570e+01],\n",
       "        [-2.7550e-01,  2.2522e+00],\n",
       "        [-2.0477e+00,  8.9007e+00],\n",
       "        [-3.0427e+00,  1.3611e+01],\n",
       "        [ 3.4265e+00, -1.2649e+01],\n",
       "        [-1.2444e+00,  6.7684e-01],\n",
       "        [ 7.2951e-01,  3.5576e+00],\n",
       "        [ 1.9621e+00,  8.9850e-01],\n",
       "        [-2.4396e+00,  7.0978e+00],\n",
       "        [-4.7962e+00, -8.8906e+00],\n",
       "        [-1.2516e+00, -7.3067e+00],\n",
       "        [-1.7492e+00, -1.2294e+01],\n",
       "        [-1.0636e+00,  3.2063e+00],\n",
       "        [-3.2573e+00, -7.6979e-01],\n",
       "        [ 3.5793e+00, -1.5420e+00],\n",
       "        [ 1.3896e-01, -1.2940e+00],\n",
       "        [ 1.0119e+00,  9.5376e+00],\n",
       "        [ 4.7362e+00,  9.5258e+00],\n",
       "        [ 4.7471e+00, -1.0848e+00],\n",
       "        [-4.4916e+00, -7.1112e+00],\n",
       "        [ 3.4045e+00, -9.7237e-02],\n",
       "        [-2.4852e+00, -1.1495e+01],\n",
       "        [-4.6793e+00, -1.2660e+01],\n",
       "        [-1.0142e+00,  8.2261e+00],\n",
       "        [ 2.7032e+00, -1.4466e+01],\n",
       "        [ 3.1189e+00, -1.1738e+01],\n",
       "        [-1.0571e+00, -6.0821e+00],\n",
       "        [-9.6308e-01, -2.9451e+00],\n",
       "        [-4.4867e+00, -1.2952e+01],\n",
       "        [-7.8240e-01,  1.9398e-01],\n",
       "        [-2.2714e+00,  5.6505e+00],\n",
       "        [-4.5003e+00, -1.0123e+00],\n",
       "        [ 4.3971e+00, -6.1184e+00],\n",
       "        [ 4.5150e+00,  5.4323e+00],\n",
       "        [-4.5123e+00,  9.4905e+00],\n",
       "        [-5.7697e-01, -6.6961e+00],\n",
       "        [ 3.9983e+00, -1.2121e+01],\n",
       "        [ 5.3652e-01, -3.1405e+00],\n",
       "        [ 3.5706e+00,  4.1872e+00],\n",
       "        [ 2.4025e+00,  5.2974e+00],\n",
       "        [-1.2024e+00, -3.1546e+00],\n",
       "        [-4.1204e+00,  8.1277e+00],\n",
       "        [ 3.9699e+00,  1.0263e+01],\n",
       "        [-3.5269e+00,  6.6900e-01],\n",
       "        [-3.5247e+00, -8.2573e+00],\n",
       "        [-2.9135e+00,  5.1262e+00],\n",
       "        [-2.9796e+00, -3.2726e-01],\n",
       "        [ 2.1034e-01,  9.6693e+00],\n",
       "        [-3.7796e+00, -1.0298e+01],\n",
       "        [-2.9033e+00,  1.0499e+01],\n",
       "        [-1.7973e+00,  1.2652e+01],\n",
       "        [ 1.8080e+00,  1.8994e+00],\n",
       "        [-3.7220e-02, -2.9652e+00],\n",
       "        [ 6.2733e-01, -3.4252e+00],\n",
       "        [-3.5132e-02,  1.9139e+00],\n",
       "        [-3.9110e+00, -7.8620e+00],\n",
       "        [ 4.0375e+00, -1.2173e+01],\n",
       "        [-3.5903e-01,  1.4839e+01],\n",
       "        [ 1.8062e+00,  4.2470e-01],\n",
       "        [-4.3330e+00,  7.4307e+00],\n",
       "        [-3.5614e+00, -4.2580e+00],\n",
       "        [-1.6776e+00, -2.2213e+00],\n",
       "        [ 5.4691e-02,  1.2372e+01],\n",
       "        [ 6.2419e-01,  1.3435e+01],\n",
       "        [ 3.0586e+00, -9.4832e+00],\n",
       "        [ 2.2425e+00, -1.0603e+01],\n",
       "        [-2.1191e+00,  4.4118e+00],\n",
       "        [ 1.6510e+00,  1.1253e+01],\n",
       "        [-1.6096e+00,  2.4013e-02],\n",
       "        [ 2.5741e+00, -1.4506e+01],\n",
       "        [ 3.6149e+00, -1.2404e+01],\n",
       "        [ 6.8913e-02, -2.5503e+00],\n",
       "        [-2.6334e+00,  1.9826e+00],\n",
       "        [ 4.1346e+00, -4.3848e+00],\n",
       "        [-2.9685e+00, -5.5476e+00],\n",
       "        [-4.9557e+00,  6.7709e+00],\n",
       "        [-2.4013e+00, -1.0010e+01],\n",
       "        [-2.8805e+00,  8.6243e+00],\n",
       "        [ 2.6479e+00,  1.1513e+01],\n",
       "        [ 1.8136e+00, -5.0094e+00],\n",
       "        [-1.3972e+00,  4.4314e+00],\n",
       "        [ 4.1102e+00,  4.0784e+00],\n",
       "        [-2.3657e+00, -7.0512e+00],\n",
       "        [-4.7273e+00,  3.2407e+00],\n",
       "        [-2.8059e+00, -1.3374e+01],\n",
       "        [ 4.3844e+00, -9.7412e+00],\n",
       "        [-5.6881e-01,  4.2974e+00],\n",
       "        [ 1.5929e-01, -1.0093e+01],\n",
       "        [-4.0416e+00,  1.1956e+01],\n",
       "        [ 8.1419e-01,  1.2444e+01],\n",
       "        [-1.6762e+00,  4.4183e+00],\n",
       "        [-1.1434e+00, -6.6707e-01],\n",
       "        [-3.0452e+00,  5.0730e+00],\n",
       "        [ 1.5808e+00, -3.0943e-01],\n",
       "        [-1.1245e+00, -9.2464e+00],\n",
       "        [ 3.4577e+00, -1.1166e+01],\n",
       "        [ 2.0483e+00, -5.0438e+00],\n",
       "        [-2.4123e+00,  2.6947e+00],\n",
       "        [-2.5973e+00,  3.4561e+00],\n",
       "        [ 9.8190e-01, -1.1137e+01],\n",
       "        [ 8.3249e-01,  6.3889e+00],\n",
       "        [ 1.9792e+00, -1.8882e+00],\n",
       "        [-4.0989e+00, -2.3123e+00],\n",
       "        [ 1.7365e+00, -5.4732e+00],\n",
       "        [ 1.8979e+00,  9.9894e+00],\n",
       "        [-2.6108e+00,  1.4793e-01],\n",
       "        [ 2.0675e+00,  1.1757e+00],\n",
       "        [ 4.1766e-01,  1.8730e+00],\n",
       "        [-3.9307e+00,  1.1788e+00],\n",
       "        [ 3.4623e+00,  1.3517e+01],\n",
       "        [ 2.9388e+00,  2.0100e+00],\n",
       "        [ 2.3351e+00, -7.2972e+00],\n",
       "        [-4.1434e+00, -1.2899e+01],\n",
       "        [ 4.9880e+00,  9.5218e+00],\n",
       "        [-3.4562e+00,  5.8686e+00],\n",
       "        [ 3.7758e+00,  1.4994e+01],\n",
       "        [ 4.3720e+00,  1.1621e+01],\n",
       "        [-1.1463e+00, -5.2641e+00],\n",
       "        [ 4.1052e+00,  8.4057e+00],\n",
       "        [-3.0089e+00,  1.3485e+01],\n",
       "        [ 2.4158e+00,  8.1770e+00],\n",
       "        [-3.1339e+00,  4.3035e+00],\n",
       "        [-1.7528e+00,  1.1720e+01],\n",
       "        [-8.9970e-01,  5.8397e+00],\n",
       "        [ 8.8811e-01,  6.3820e+00],\n",
       "        [-1.6991e+00,  7.3136e+00],\n",
       "        [-3.4924e+00,  3.3878e+00],\n",
       "        [-3.3830e+00, -1.4798e+01],\n",
       "        [-4.0153e+00,  1.1842e+01],\n",
       "        [ 2.7052e+00,  1.4073e+01],\n",
       "        [ 4.0056e+00, -1.3396e+01],\n",
       "        [-3.4122e+00, -2.4237e+00],\n",
       "        [-3.2472e+00,  1.0416e+01],\n",
       "        [-3.7800e+00, -7.3185e+00],\n",
       "        [-4.8305e+00, -8.5162e+00],\n",
       "        [ 4.1124e+00,  1.2281e+01],\n",
       "        [ 3.5792e+00,  1.1582e+01],\n",
       "        [ 4.4459e+00, -3.8409e+00],\n",
       "        [ 2.2000e+00,  1.3364e+01],\n",
       "        [ 1.6541e+00,  1.4995e+01],\n",
       "        [ 2.5933e+00,  9.3247e+00],\n",
       "        [-1.7500e+00,  7.1974e+00],\n",
       "        [ 5.7453e-01, -3.5823e+00],\n",
       "        [-2.8185e+00, -8.4167e+00],\n",
       "        [-3.8474e+00,  1.0070e+01],\n",
       "        [ 3.5547e+00, -1.7072e+00],\n",
       "        [-2.8934e+00,  1.1594e+01],\n",
       "        [ 3.1974e+00,  1.1150e+00],\n",
       "        [-2.3607e+00,  1.3786e+01],\n",
       "        [ 2.0447e+00, -1.1387e+01],\n",
       "        [ 4.7854e+00,  1.1391e+01],\n",
       "        [-1.8225e+00,  8.4323e+00],\n",
       "        [-2.8409e+00, -2.3507e+00],\n",
       "        [ 4.2455e+00,  6.1979e-01],\n",
       "        [-3.5361e+00, -5.0135e+00],\n",
       "        [-1.3572e+00, -2.8939e+00],\n",
       "        [ 4.7850e-01,  1.3872e+01],\n",
       "        [ 2.6770e-01, -9.2616e+00],\n",
       "        [ 2.5627e-01,  7.1923e+00],\n",
       "        [ 2.4802e+00, -1.3709e+01],\n",
       "        [-8.9471e-01, -1.1147e+01],\n",
       "        [-2.1334e+00,  5.4044e+00],\n",
       "        [-3.5507e+00,  5.5759e+00],\n",
       "        [ 4.2439e+00,  9.8383e-01],\n",
       "        [-3.3324e+00, -5.3743e+00],\n",
       "        [ 1.0918e+00, -1.1435e+01],\n",
       "        [ 2.4841e+00, -1.3618e+01],\n",
       "        [-4.8065e+00, -1.4575e+01],\n",
       "        [-1.0143e+00,  1.0086e+01],\n",
       "        [-4.7324e+00,  1.2468e+01],\n",
       "        [-2.0001e+00,  4.3933e+00],\n",
       "        [ 2.2801e-01, -1.3526e+01],\n",
       "        [ 4.1466e+00,  8.0767e+00],\n",
       "        [ 4.9700e+00,  7.5782e+00],\n",
       "        [-3.3003e+00,  1.2519e+01],\n",
       "        [ 2.6872e-01,  7.1132e+00],\n",
       "        [-4.0091e+00, -4.3144e+00],\n",
       "        [-4.9094e+00, -5.8424e+00],\n",
       "        [ 1.0787e+00, -1.1777e+01],\n",
       "        [ 1.5938e+00,  8.0521e+00],\n",
       "        [ 6.9655e-01, -1.0036e+01],\n",
       "        [-3.8766e+00, -4.6277e+00],\n",
       "        [ 2.1948e+00,  1.4796e+01],\n",
       "        [ 2.8751e+00, -1.6891e+00],\n",
       "        [ 1.7531e+00, -1.4716e+01],\n",
       "        [-4.2705e+00,  6.9991e+00],\n",
       "        [-2.8321e+00,  7.2164e+00],\n",
       "        [-3.5297e+00, -7.4297e+00],\n",
       "        [-4.1184e+00,  7.8276e+00],\n",
       "        [-5.0948e-01,  1.1544e+01],\n",
       "        [ 3.0944e+00,  8.3001e+00],\n",
       "        [ 1.6078e-01, -4.6377e+00],\n",
       "        [-1.0872e+00,  1.9935e+00],\n",
       "        [ 2.4785e+00, -1.0509e+01],\n",
       "        [ 4.1964e+00, -1.6310e+00],\n",
       "        [-4.1897e+00, -8.1159e+00],\n",
       "        [ 4.4241e+00,  1.3718e+01],\n",
       "        [-4.6314e+00,  1.0579e+01],\n",
       "        [ 2.5058e+00,  8.8788e+00],\n",
       "        [ 4.2326e+00, -8.0843e+00],\n",
       "        [ 1.5789e+00,  6.1385e+00],\n",
       "        [-1.4775e+00,  5.0198e+00],\n",
       "        [-1.4386e+00,  9.2739e+00],\n",
       "        [-1.3873e+00, -5.5919e+00],\n",
       "        [ 1.2587e+00,  5.3204e+00],\n",
       "        [-2.4429e+00,  1.3260e+00],\n",
       "        [ 2.8977e+00, -1.4925e+00],\n",
       "        [ 1.5217e+00, -3.6178e+00],\n",
       "        [ 1.7525e+00, -1.0866e+01],\n",
       "        [-2.9401e+00, -7.6139e+00],\n",
       "        [ 4.5951e+00, -4.0363e+00],\n",
       "        [-1.3652e-02, -7.2674e+00],\n",
       "        [ 4.9915e+00,  1.4650e+01],\n",
       "        [-3.7709e+00, -1.2160e+01],\n",
       "        [-3.7900e+00, -7.2341e-02],\n",
       "        [-1.2745e+00, -9.8182e+00],\n",
       "        [-1.7934e+00,  2.8340e+00],\n",
       "        [-2.6125e+00,  3.3237e+00],\n",
       "        [-1.1466e+00, -7.2685e+00],\n",
       "        [ 6.8693e-01,  1.2334e+01],\n",
       "        [-3.3804e+00,  6.9652e-01],\n",
       "        [-1.8438e+00,  1.4720e+01],\n",
       "        [-4.7438e+00, -1.4380e+01],\n",
       "        [ 4.9269e+00, -9.4903e+00],\n",
       "        [ 9.5862e-01, -1.2946e+00],\n",
       "        [-1.0533e+00, -3.3502e+00],\n",
       "        [ 3.1772e+00,  7.1695e-01],\n",
       "        [-4.8681e+00, -8.8554e+00],\n",
       "        [-1.7045e+00,  7.5482e+00],\n",
       "        [-3.2357e+00,  1.4144e+01],\n",
       "        [-1.1136e+00, -2.6934e+00],\n",
       "        [ 3.9178e+00,  7.5391e+00],\n",
       "        [ 4.2406e+00,  8.6767e+00],\n",
       "        [-1.5168e+00, -9.9521e+00],\n",
       "        [-3.7202e-01,  1.2415e+01],\n",
       "        [-1.6781e+00, -1.3911e+01],\n",
       "        [ 2.0496e+00,  1.4602e+01],\n",
       "        [-1.4234e+00, -1.2420e+01],\n",
       "        [-4.5353e+00,  3.7590e+00],\n",
       "        [-3.7860e-01, -7.5748e+00],\n",
       "        [ 1.0107e+00,  5.6964e+00],\n",
       "        [ 3.9766e+00,  1.1646e+01],\n",
       "        [-7.4842e-01, -1.3227e+01],\n",
       "        [-4.5181e+00,  1.4005e+01],\n",
       "        [ 2.2103e+00,  6.5386e+00],\n",
       "        [-4.3261e+00,  1.3890e+01],\n",
       "        [ 4.7367e+00,  1.3543e+01],\n",
       "        [-4.2179e+00, -5.6599e+00],\n",
       "        [-3.4388e+00,  1.4204e+01]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.4378e+00],\n",
       "        [-3.7890e+00],\n",
       "        [-2.5952e+00],\n",
       "        [-7.3753e-01],\n",
       "        [-4.4356e+00],\n",
       "        [-4.3357e+00],\n",
       "        [ 1.3836e+00],\n",
       "        [-3.7483e+00],\n",
       "        [-1.2653e+00],\n",
       "        [-4.0966e+00],\n",
       "        [-3.2285e+00],\n",
       "        [ 1.0745e+01],\n",
       "        [-4.5013e+00],\n",
       "        [-7.2812e+00],\n",
       "        [-3.4633e+00],\n",
       "        [-1.4592e+00],\n",
       "        [-7.5205e+00],\n",
       "        [-1.3306e+00],\n",
       "        [ 3.2050e+00],\n",
       "        [ 5.3060e+00],\n",
       "        [-3.8119e+00],\n",
       "        [ 1.7163e+00],\n",
       "        [-4.1767e+00],\n",
       "        [-1.9737e-01],\n",
       "        [ 2.6804e+00],\n",
       "        [ 8.2850e+00],\n",
       "        [ 3.5710e+00],\n",
       "        [-3.1805e+00],\n",
       "        [ 9.2787e-01],\n",
       "        [-6.0633e+00],\n",
       "        [ 2.6105e+00],\n",
       "        [-5.3974e-03],\n",
       "        [ 9.3413e-01],\n",
       "        [-4.0694e+00],\n",
       "        [-4.8873e-01],\n",
       "        [ 4.1689e+00],\n",
       "        [ 5.9016e+00],\n",
       "        [ 2.5146e+00],\n",
       "        [-1.0889e+01],\n",
       "        [ 9.8984e+00],\n",
       "        [ 2.9398e+00],\n",
       "        [ 7.1161e-01],\n",
       "        [ 6.0663e+00],\n",
       "        [-2.4172e-01],\n",
       "        [ 4.2747e+00],\n",
       "        [-3.8776e+00],\n",
       "        [ 1.4719e+00],\n",
       "        [-2.2886e+00],\n",
       "        [ 2.6969e+00],\n",
       "        [-2.7041e+00],\n",
       "        [-6.9853e+00],\n",
       "        [-1.7980e+00],\n",
       "        [-2.3313e+00],\n",
       "        [-3.2705e+00],\n",
       "        [-9.3894e+00],\n",
       "        [ 1.0142e+01],\n",
       "        [-5.2339e-01],\n",
       "        [ 4.4696e-01],\n",
       "        [ 2.4580e+00],\n",
       "        [-5.3218e+00],\n",
       "        [-5.2141e+00],\n",
       "        [-2.5772e-01],\n",
       "        [ 1.2377e+00],\n",
       "        [-3.5534e+00],\n",
       "        [-5.6161e+00],\n",
       "        [ 3.8272e+00],\n",
       "        [ 6.9340e-01],\n",
       "        [-1.9368e+00],\n",
       "        [ 5.4578e+00],\n",
       "        [ 8.3666e+00],\n",
       "        [-6.2901e+00],\n",
       "        [ 3.2291e+00],\n",
       "        [-4.1079e-02],\n",
       "        [-3.2278e+00],\n",
       "        [-4.1284e+00],\n",
       "        [ 9.2046e+00],\n",
       "        [ 7.8608e+00],\n",
       "        [ 1.4334e+00],\n",
       "        [-1.0523e-01],\n",
       "        [-2.7652e+00],\n",
       "        [-5.6391e-01],\n",
       "        [-3.2641e+00],\n",
       "        [-7.6443e+00],\n",
       "        [ 8.9856e+00],\n",
       "        [ 6.3476e+00],\n",
       "        [-8.7421e+00],\n",
       "        [-9.0054e-02],\n",
       "        [ 9.1327e+00],\n",
       "        [ 3.0606e-01],\n",
       "        [ 3.9562e+00],\n",
       "        [ 1.8665e+00],\n",
       "        [-8.4009e-01],\n",
       "        [-1.0071e+01],\n",
       "        [ 4.1571e+00],\n",
       "        [-6.6582e+00],\n",
       "        [-3.2961e+00],\n",
       "        [-6.0504e+00],\n",
       "        [-3.8552e+00],\n",
       "        [-2.8166e+00],\n",
       "        [-2.9113e+00],\n",
       "        [-6.9705e+00],\n",
       "        [-5.4318e+00],\n",
       "        [ 3.5144e+00],\n",
       "        [-8.0379e-01],\n",
       "        [ 2.7561e+00],\n",
       "        [-1.9694e+00],\n",
       "        [-3.5920e+00],\n",
       "        [ 1.1169e+01],\n",
       "        [-4.6563e+00],\n",
       "        [ 2.9372e+00],\n",
       "        [-8.9522e+00],\n",
       "        [-2.6283e+00],\n",
       "        [-1.6621e+00],\n",
       "        [-4.5903e+00],\n",
       "        [-1.1019e+00],\n",
       "        [ 9.3502e+00],\n",
       "        [ 7.2720e+00],\n",
       "        [-4.5296e+00],\n",
       "        [-1.6122e+00],\n",
       "        [-1.9486e+00],\n",
       "        [ 9.4129e+00],\n",
       "        [ 8.2467e+00],\n",
       "        [ 4.8788e-01],\n",
       "        [-3.3023e+00],\n",
       "        [ 5.6034e+00],\n",
       "        [-2.4207e+00],\n",
       "        [-9.0241e+00],\n",
       "        [-1.1710e+00],\n",
       "        [-6.1812e+00],\n",
       "        [-5.3079e-01],\n",
       "        [ 4.7191e+00],\n",
       "        [-4.8901e+00],\n",
       "        [ 5.0387e+00],\n",
       "        [-1.0911e+00],\n",
       "        [-7.5282e+00],\n",
       "        [-3.5662e-01],\n",
       "        [ 1.0212e+01],\n",
       "        [-2.3764e+00],\n",
       "        [ 2.8611e+00],\n",
       "        [-7.9663e+00],\n",
       "        [-3.4615e+00],\n",
       "        [-4.1092e+00],\n",
       "        [-2.8226e+00],\n",
       "        [-5.6242e+00],\n",
       "        [ 2.2998e+00],\n",
       "        [ 1.6378e+00],\n",
       "        [ 8.4866e+00],\n",
       "        [ 5.3126e+00],\n",
       "        [-6.3176e+00],\n",
       "        [-4.3240e+00],\n",
       "        [ 5.9793e+00],\n",
       "        [ 7.2486e-01],\n",
       "        [ 4.6654e+00],\n",
       "        [-6.2757e+00],\n",
       "        [ 4.7203e+00],\n",
       "        [ 9.5780e-01],\n",
       "        [-5.0174e+00],\n",
       "        [ 6.9545e-01],\n",
       "        [ 4.7673e-01],\n",
       "        [-6.8129e+00],\n",
       "        [ 1.5969e+00],\n",
       "        [ 3.9755e+00],\n",
       "        [ 6.1076e+00],\n",
       "        [-1.6243e+00],\n",
       "        [ 5.3900e+00],\n",
       "        [-6.7794e+00],\n",
       "        [ 2.8957e+00],\n",
       "        [ 3.6820e+00],\n",
       "        [-1.7138e+00],\n",
       "        [ 3.2914e+00],\n",
       "        [-9.5214e+00],\n",
       "        [ 3.4394e+00],\n",
       "        [-6.0983e+00],\n",
       "        [-5.2450e+00],\n",
       "        [-3.1077e+00],\n",
       "        [-4.5893e-01],\n",
       "        [-5.0948e+00],\n",
       "        [-7.9170e+00],\n",
       "        [-2.1386e+00],\n",
       "        [-1.0310e+01],\n",
       "        [ 7.4061e-01],\n",
       "        [ 9.5477e+00],\n",
       "        [-4.9286e+00],\n",
       "        [-8.1044e+00],\n",
       "        [-3.7320e+00],\n",
       "        [-5.9017e+00],\n",
       "        [ 2.7368e+00],\n",
       "        [ 1.0752e+00],\n",
       "        [ 7.8645e+00],\n",
       "        [-1.1452e+00],\n",
       "        [-9.9805e-01],\n",
       "        [ 1.4152e+00],\n",
       "        [-5.4388e+00],\n",
       "        [ 2.4847e+00],\n",
       "        [-8.3092e-01],\n",
       "        [-8.6299e+00],\n",
       "        [ 4.6218e+00],\n",
       "        [-8.6261e+00],\n",
       "        [ 4.3910e+00],\n",
       "        [-7.9481e+00],\n",
       "        [ 6.4866e+00],\n",
       "        [ 3.8518e+00],\n",
       "        [-5.3011e+00],\n",
       "        [-2.6900e+00],\n",
       "        [ 5.5105e+00],\n",
       "        [-4.2758e+00],\n",
       "        [ 8.8693e-01],\n",
       "        [-2.8305e+00],\n",
       "        [ 4.5501e+00],\n",
       "        [-2.0451e+00],\n",
       "        [ 8.0243e+00],\n",
       "        [ 9.0360e-01],\n",
       "        [-5.6351e+00],\n",
       "        [-9.0222e+00],\n",
       "        [ 5.1294e+00],\n",
       "        [-4.1619e+00],\n",
       "        [ 4.9945e+00],\n",
       "        [ 8.2949e+00],\n",
       "        [-4.4395e+00],\n",
       "        [-3.2806e+00],\n",
       "        [-1.0575e+01],\n",
       "        [-3.2433e+00],\n",
       "        [ 4.3421e+00],\n",
       "        [ 5.5138e+00],\n",
       "        [ 4.1597e+00],\n",
       "        [-9.1312e+00],\n",
       "        [-2.5705e+00],\n",
       "        [-5.5991e+00],\n",
       "        [-6.9165e+00],\n",
       "        [ 5.5206e+00],\n",
       "        [-3.1189e-01],\n",
       "        [ 3.4349e+00],\n",
       "        [-5.1581e+00],\n",
       "        [ 1.9156e-01],\n",
       "        [ 6.5358e+00],\n",
       "        [ 6.2809e+00],\n",
       "        [-7.9546e+00],\n",
       "        [-7.2509e+00],\n",
       "        [-3.3320e+00],\n",
       "        [-1.0087e+01],\n",
       "        [-4.5574e+00],\n",
       "        [ 2.4293e+00],\n",
       "        [ 1.2904e+00],\n",
       "        [-4.0920e-01],\n",
       "        [ 5.6878e+00],\n",
       "        [ 6.7756e+00],\n",
       "        [-3.4926e+00],\n",
       "        [ 4.6820e+00],\n",
       "        [-8.6978e+00],\n",
       "        [ 2.2247e+00],\n",
       "        [ 7.3394e+00],\n",
       "        [ 1.4307e+00],\n",
       "        [-3.8110e+00],\n",
       "        [-3.5990e+00],\n",
       "        [-1.5558e+00],\n",
       "        [ 7.9449e-01],\n",
       "        [-5.7896e+00],\n",
       "        [ 2.3927e+00],\n",
       "        [ 2.1682e+00],\n",
       "        [ 4.9593e+00],\n",
       "        [ 8.1799e-01],\n",
       "        [ 7.4545e+00],\n",
       "        [ 1.0062e+00],\n",
       "        [ 2.6697e+00],\n",
       "        [-1.4853e+00],\n",
       "        [-7.8609e+00],\n",
       "        [ 3.6453e-01],\n",
       "        [-2.9682e+00],\n",
       "        [-4.9995e+00],\n",
       "        [ 2.3434e-01],\n",
       "        [-2.4574e+00],\n",
       "        [-5.7833e+00],\n",
       "        [-6.6259e+00],\n",
       "        [-2.7505e+00],\n",
       "        [ 1.0495e+01],\n",
       "        [ 2.7555e+00],\n",
       "        [-1.4386e+00],\n",
       "        [ 4.9617e+00],\n",
       "        [-4.8051e+00],\n",
       "        [-2.3594e+00],\n",
       "        [-1.1138e+01],\n",
       "        [-3.8279e+00],\n",
       "        [ 3.1611e+00],\n",
       "        [ 4.6656e+00],\n",
       "        [-1.1246e+00],\n",
       "        [-4.9920e+00],\n",
       "        [ 1.9481e+00],\n",
       "        [-1.4856e+00],\n",
       "        [ 2.4543e+00],\n",
       "        [-7.6210e+00],\n",
       "        [ 1.3286e+00],\n",
       "        [-1.4790e+00],\n",
       "        [ 1.7625e+00],\n",
       "        [ 1.9919e+00],\n",
       "        [-1.1254e+01],\n",
       "        [ 6.9641e-01],\n",
       "        [-1.0334e+01],\n",
       "        [ 3.8736e+00],\n",
       "        [-6.4887e+00],\n",
       "        [-1.0090e+01]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.3897, -6.5319]), tensor([-3.7483]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.3897, -6.5319]), tensor([-3.7483]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[7], Y[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, w_true, n_features, n_objects):\n",
    "        self.X = (torch.rand(n_objects, n_features) - 0.5) * 10\n",
    "        self.X *= (torch.arange(n_features) * 2 + 1)\n",
    "        self.Y = self.X @ w_true + torch.randn(n_objects)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.X[item], self.Y[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(w_true, n_features, n_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.4391, 9.1902]), tensor(4.4021))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.4391, 9.1902])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=4, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Общая структура обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for x, y in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(x)\n",
    "\n",
    "    loss = loss_fn(output, y)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in tqdm(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(model: nn.Module, data_loader: DataLoader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, y in tqdm(data_loader):\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "\n",
    "def plot_stats(\n",
    "    train_loss: list[float],\n",
    "    valid_loss: list[float],\n",
    "    title: str\n",
    "):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' loss')\n",
    "\n",
    "    plt.plot(train_loss, label='Train loss')\n",
    "    plt.plot(valid_loss, label='Valid loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def fit(model, train_loader, valid_loader, optimizer, loss_fn, num_epochs, title):\n",
    "    train_loss_history, valid_loss_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn)\n",
    "        valid_loss = evaluate(model, valid_loader, loss_fn)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "        plot_stats(train_loss_history, valid_loss_history, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Обучение первой нейросети в `PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTaskNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(n_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "model = CustomTaskNetwork()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "train_dataset, valid_dataset = random_split(\n",
    "    dataset,\n",
    "    (int(len(dataset) * 0.8), len(dataset) -  int(len(dataset) * 0.8)),\n",
    "    generator=torch.Generator().manual_seed(300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, train_loader, valid_loader, optimizer, loss_fn, 10, 'Simple fc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
